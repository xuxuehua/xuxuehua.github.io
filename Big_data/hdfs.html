<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/static/css/tango.css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>hdfs - Xu XueHua</title>
    <meta name="keywords" content="Xu XueHua"/>
    <meta name="description" content="Xu XueHua's public notes"/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
    <div id="container">
      
<div id="header">
  <div class="post-nav"><a href="/">Home</a>&nbsp;&#187;&nbsp;<a href="/#Big_data">Big_data</a>&nbsp;&#187;&nbsp;hdfs
    <span class="updated">Page Updated&nbsp;
      2019-06-12 14:40
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">hdfs</div>

  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#hdfs">HDFS</a><ul>
<li><a href="#_1">特点</a></li>
<li><a href="#_2">高可用设计</a><ul>
<li><a href="#_3">数据存储故障容错</a></li>
<li><a href="#_4">磁盘故障容错</a></li>
<li><a href="#datanode">DataNode故障容错</a></li>
<li><a href="#namenode">NameNode故障容错</a><ul>
<li><a href="#namenode_1">NameNode 高可用</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#_5">原理</a><ul>
<li><a href="#datanode_1">DataNode</a></li>
<li><a href="#namenode_2">NameNode</a></li>
</ul>
</li>
<li><a href="#installation">Installation 伪分布式</a><ul>
<li><a href="#jdk">jdk</a></li>
<li><a href="#hadoop">hadoop</a><ul>
<li><a href="#hdfs_1">启动hdfs</a></li>
</ul>
</li>
<li><a href="#mysql">mysql</a></li>
</ul>
</li>
</ul>
</div>
<h1 id="hdfs">HDFS</h1>
<p>这些年来，各种计算框架、各种算法、各种应用场景不断推陈出新，让人眼花缭乱，但是大数据存储的王者依然是HDFS。</p>
<h2 id="_1">特点</h2>
<p>HDFS作为最早的大数据存储系统，存储着宝贵的数据资产，各种新的算法、框架要想得到人们的广泛使用，必须支持HDFS才能获取已经存储在里面的数据。所以大数据技术越发展，新技术越多，HDFS得到的支持越多，我们越离不开HDFS。<strong>HDFS也许不是最好的大数据存储技术，但依然最重要的大数据存储技术</strong>。</p>
<h2 id="_2">高可用设计</h2>
<h3 id="_3">数据存储故障容错</h3>
<p>磁盘介质在存储过程中受环境或者老化影响，其存储的数据可能会出现错乱。HDFS的应对措施是，对于存储在DataNode上的数据块，计算并存储校验和（CheckSum）。在读取数据的时候，重新计算读取出来的数据的校验和，如果校验不正确就抛出异常，应用程序捕获异常后就到其他DataNode上读取备份数据。</p>
<h3 id="_4">磁盘故障容错</h3>
<p>如果DataNode监测到本机的某块磁盘损坏，就将该块磁盘上存储的所有BlockID报告给NameNode，NameNode检查这些数据块还在哪些DataNode上有备份，通知相应的DataNode服务器将对应的数据块复制到其他服务器上，以保证数据块的备份数满足要求。</p>
<h3 id="datanode">DataNode故障容错</h3>
<p>DataNode会通过心跳和NameNode保持通信，如果DataNode超时未发送心跳，NameNode就会认为这个DataNode已经宕机失效，立即查找这个DataNode上存储的数据块有哪些，以及这些数据块还存储在哪些服务器上，随后通知这些服务器再复制一份数据块到其他服务器上，保证HDFS存储的数据块备份数符合用户设置的数目，即使再出现服务器宕机，也不会丢失数据。</p>
<h3 id="namenode">NameNode故障容错</h3>
<p>NameNode是整个HDFS的核心，记录着HDFS文件分配表信息，所有的文件路径和数据块存储信息都保存在NameNode，如果NameNode故障，整个HDFS系统集群都无法使用；如果NameNode上记录的数据丢失，整个集群所有DataNode存储的数据也就没用了。</p>
<h4 id="namenode_1">NameNode 高可用</h4>
<p>NameNode高可用容错能力非常重要。NameNode采用主从热备的方式提供高可用服务</p>
<p><img alt="img" src="https://snag.gy/rXqWt0.jpg" /></p>
<p>集群部署两台NameNode服务器，一台作为主服务器提供服务，一台作为从服务器进行热备，两台服务器通过ZooKeeper选举，主要是通过争夺znode锁资源，决定谁是主服务器。而DataNode则会向两个NameNode同时发送心跳数据，但是只有主NameNode才能向DataNode返回控制信息。</p>
<p>正常运行期间，主从NameNode之间通过一个共享存储系统shared edits来同步文件系统的元数据信息。当主NameNode服务器宕机，从NameNode会通过ZooKeeper升级成为主服务器，并保证HDFS集群的元数据信息，也就是文件分配表信息完整一致。</p>
<h1 id="_5">原理</h1>
<p>和RAID在多个磁盘上进行文件存储及并行读写的思路一样，HDFS是在一个大规模分布式服务器集群上，对数据分片后进行并行读写及冗余存储。因为HDFS可以部署在一个比较大的服务器集群上，集群中所有服务器的磁盘都可供HDFS使用，所以整个HDFS的存储空间可以达到PB级容量。</p>
<p><img alt="img" src="https://snag.gy/1X9pr5.jpg" /></p>
<h2 id="datanode_1">DataNode</h2>
<p><strong>DataNode负责文件数据的存储和读写操作，HDFS将文件数据分割成若干数据块（Block），每个DataNode存储一部分数据块，这样文件就分布存储在整个HDFS服务器集群中</strong>。应用程序客户端（Client）可以并行对这些数据块进行访问，从而使得HDFS可以在服务器集群规模上实现数据并行访问，极大地提高了访问速度。</p>
<p>在实践中，HDFS集群的DataNode服务器会有很多台，一般在几百台到几千台这样的规模，每台服务器配有数块磁盘，整个集群的存储容量大概在几PB到数百PB。</p>
<h2 id="namenode_2">NameNode</h2>
<p><strong>NameNode负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、数据块的ID以及存储位置等信息，相当于操作系统中文件分配表（FAT）的角色</strong>。HDFS为了保证数据的高可用，会将一个数据块复制为多份（缺省情况为3份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上。这样当有磁盘损坏，或者某个DataNode服务器宕机，甚至某个交换机宕机，导致其存储的数据块不能访问的时候，客户端会查找其备份的数据块进行访问。</p>
<h1 id="installation">Installation 伪分布式</h1>
<p>single-node in a pseudo-distributed mode</p>
<p>https://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0/hadoop-project-dist/hadoop-common/SingleCluster.html</p>
<div class="hlcode"><pre><span class="n">yum</span> <span class="o">-</span><span class="n">y</span> <span class="n">install</span> <span class="n">vim</span>
</pre></div>


<h2 id="jdk">jdk</h2>
<div class="hlcode"><pre><span class="nl">http:</span><span class="c1">//mirror.cnop.net/jdk/linux/jdk-7u79-linux-x64.tar.gz</span>
</pre></div>


<div class="hlcode"><pre><span class="n">vim</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">hostname</span>
<span class="n">vim</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">hosts</span>
<span class="n">hadoop000</span>

<span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">~/</span><span class="n">app</span><span class="o">/</span><span class="n">tmp</span>
<span class="n">tar</span> <span class="o">-</span><span class="n">xf</span> <span class="n">jdk</span><span class="o">-</span><span class="mi">7u79</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x64</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">gz</span> <span class="o">-</span><span class="n">C</span> <span class="o">~/</span><span class="n">app</span><span class="o">/</span>

<span class="n">cp</span> <span class="o">~/</span><span class="p">.</span><span class="n">ssh</span><span class="o">/</span><span class="n">id_rsa</span><span class="p">.</span><span class="n">pub</span> <span class="o">~/</span><span class="p">.</span><span class="n">ssh</span><span class="o">/</span><span class="n">authorized_keys</span>

<span class="n">vim</span> <span class="o">~/</span><span class="p">.</span><span class="n">bash_profile</span>
<span class="n">export</span> <span class="n">JAVA_HOME</span><span class="o">=/</span><span class="n">home</span><span class="o">/</span><span class="n">hadoop</span><span class="o">/</span><span class="n">app</span><span class="o">/</span><span class="n">jdk1</span><span class="mf">.7.0</span><span class="n">_79</span>
<span class="n">export</span> <span class="n">PATH</span><span class="o">=</span><span class="err">$</span><span class="n">JAVA_HOME</span><span class="o">/</span><span class="n">bin</span><span class="o">:</span><span class="err">$</span><span class="n">PATH</span>

<span class="n">source</span> <span class="o">~/</span><span class="p">.</span><span class="n">bash_profile</span>
<span class="n">java</span> <span class="o">-</span><span class="n">version</span>
</pre></div>


<h2 id="hadoop">hadoop</h2>
<div class="hlcode"><pre><span class="nl">https:</span><span class="c1">//archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0.tar.gz</span>
</pre></div>


<div class="hlcode"><pre><span class="n">tar</span> <span class="o">-</span><span class="n">xf</span> <span class="n">hadoop</span><span class="o">-</span><span class="mf">2.6.0</span><span class="o">-</span><span class="n">cdh5</span><span class="mf">.7.0</span><span class="p">.</span><span class="n">tar</span><span class="p">.</span><span class="n">gz</span>  <span class="o">-</span><span class="n">C</span> <span class="o">~/</span><span class="n">app</span><span class="o">/</span>

<span class="n">vim</span>  <span class="n">etc</span><span class="o">/</span><span class="n">hadoop</span><span class="o">/</span><span class="n">hadoop</span><span class="o">-</span><span class="n">env</span><span class="p">.</span><span class="n">sh</span>
<span class="n">export</span> <span class="n">JAVA_HOME</span><span class="o">=/</span><span class="n">home</span><span class="o">/</span><span class="n">hadoop</span><span class="o">/</span><span class="n">app</span><span class="o">/</span><span class="n">jdk1</span><span class="mf">.7.0</span><span class="n">_79</span>
</pre></div>


<div class="hlcode"><pre><span class="nx">vim</span> <span class="nx">etc</span><span class="p">/</span><span class="nx">hadoop</span><span class="p">/</span><span class="nx">core</span><span class="na">-site.xml</span>
<span class="o">&lt;</span><span class="nx">configuration</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="nx">property</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nb">name</span><span class="o">&gt;</span><span class="nx">fs.defaultFS</span><span class="o">&lt;/</span><span class="nb">name</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nb">value</span><span class="o">&gt;</span><span class="nx">hdfs</span><span class="p">:</span><span class="c1">//hadoop000:8020&lt;/value&gt;</span>
    <span class="o">&lt;/</span><span class="nx">property</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="nx">property</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nb">name</span><span class="o">&gt;</span><span class="nx">hadoop.tmp.dir</span><span class="o">&lt;/</span><span class="nb">name</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nb">value</span><span class="o">&gt;/</span><span class="nb">home</span><span class="p">/</span><span class="nx">hadoop</span><span class="p">/</span><span class="nx">app</span><span class="p">/</span><span class="nx">tmp</span><span class="o">&lt;/</span><span class="nb">value</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="nx">property</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="nx">configuration</span><span class="o">&gt;</span>


<span class="nx">vim</span> <span class="nx">etc</span><span class="p">/</span><span class="nx">hadoop</span><span class="p">/</span><span class="nx">hdfs</span><span class="na">-site.xml</span>
<span class="o">&lt;</span><span class="nx">configuration</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="nx">property</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nb">name</span><span class="o">&gt;</span><span class="nx">dfs.replication</span><span class="o">&lt;/</span><span class="nb">name</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nb">value</span><span class="o">&gt;</span><span class="mi">1</span><span class="o">&lt;/</span><span class="nb">value</span><span class="o">&gt;</span>
    <span class="o">&lt;/</span><span class="nx">property</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="nx">configuration</span><span class="o">&gt;</span>
</pre></div>


<h3 id="hdfs_1">启动hdfs</h3>
<p>仅仅第一次执行即可，不需要重复执行</p>
<div class="hlcode"><pre><span class="n">bin</span><span class="o">/</span><span class="n">hdfs</span> <span class="n">namenode</span> <span class="o">-</span><span class="n">format</span>
</pre></div>


<p>启动</p>
<div class="hlcode"><pre><span class="n">sbin</span><span class="o">/</span><span class="n">start</span><span class="o">-</span><span class="n">dfs</span><span class="p">.</span><span class="n">sh</span>
</pre></div>


<p>检查状态</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">jps</span>
<span class="mi">11150</span> <span class="n">SecondaryNameNode</span>
<span class="mi">10996</span> <span class="n">DataNode</span>
<span class="mi">10881</span> <span class="n">NameNode</span>
<span class="mi">11253</span> <span class="n">Jps</span>
</pre></div>


<p>或访问</p>
<div class="hlcode"><pre><span class="nl">http:</span><span class="c1">//localhost:50070</span>
</pre></div>


<p>停止</p>
<div class="hlcode"><pre><span class="n">sbin</span><span class="o">/</span><span class="n">stop</span><span class="o">-</span><span class="n">dfs</span><span class="p">.</span><span class="n">sh</span>
</pre></div>


<div class="hlcode"><pre><span class="n">vim</span> <span class="o">~/</span><span class="p">.</span><span class="n">bash_profile</span>
<span class="n">export</span> <span class="n">HADOOP_HOME</span><span class="o">=/</span><span class="n">home</span><span class="o">/</span><span class="n">hadoop</span><span class="o">/</span><span class="n">app</span><span class="o">/</span><span class="n">hadoop</span><span class="o">-</span><span class="mf">2.6.0</span><span class="o">-</span><span class="n">cdh5</span><span class="mf">.7.0</span>
<span class="n">export</span> <span class="n">PATH</span><span class="o">=</span><span class="err">$</span><span class="n">HADOOP_HOME</span><span class="o">/</span><span class="n">bin</span><span class="o">:</span><span class="err">$</span><span class="n">PATH</span>
</pre></div>


<h2 id="mysql">mysql</h2>
<p>mysql-connector-java-5.1.27-bin.jar</p>
<div class="hlcode"><pre><span class="nl">http:</span><span class="c1">//repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.27/mysql-connector-java-5.1.27.jar</span>
</pre></div>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2020 Xu XueHua.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2020-01-24 16:55:26</p>
      </span>
    </div>

    
    
  </body>
</html>
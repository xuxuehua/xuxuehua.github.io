<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/static/css/tango.css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>basic_knowledge - Xu XueHua</title>
    <meta name="keywords" content="Xu XueHua"/>
    <meta name="description" content="Xu XueHua's public notes"/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
    <div id="container">
      
<div id="header">
  <div class="post-nav"><a href="/">Home</a>&nbsp;&#187;&nbsp;<a href="/#Big_data">Big_data</a>&nbsp;&#187;&nbsp;basic_knowledge
    <span class="updated">Page Updated&nbsp;
      2019-06-11 21:51
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">basic_knowledge</div>

  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">相关概念</a><ul>
<li><a href="#_2">大数据平台</a></li>
<li><a href="#_3">三驾马车</a></li>
<li><a href="#hdfs">HDFS</a></li>
<li><a href="#hadoop">Hadoop</a></li>
<li><a href="#pig">Pig</a></li>
<li><a href="#hive">Hive</a></li>
<li><a href="#yarn">Yarn 资源调度框架</a></li>
<li><a href="#spark">Spark</a></li>
<li><a href="#hbase">HBase</a></li>
<li><a href="#_4">分布式架构</a><ul>
<li><a href="#_5">框架设计</a></li>
</ul>
</li>
<li><a href="#sql">SQL 引擎</a></li>
</ul>
</li>
<li><a href="#_6">计算类型</a><ul>
<li><a href="#_7">批处理计算/大数据离线计算</a></li>
<li><a href="#_8">大数据流计算/大数据实时计算</a></li>
</ul>
</li>
<li><a href="#_9">应用场景</a><ul>
<li><a href="#_10">数据分析</a></li>
<li><a href="#_11">数据挖掘与机器学习</a></li>
</ul>
</li>
<li><a href="#_12">大数据计算过程</a></li>
<li><a href="#_13">分布式架构的原则</a></li>
<li><a href="#_14">大数据软件性能优化</a><ul>
<li><a href="#sql_1">SQL语句优化</a></li>
<li><a href="#_15">数据倾斜处理</a></li>
<li><a href="#mapreducespark">MapReduce、Spark代码优化</a></li>
<li><a href="#_16">配置参数优化</a></li>
<li><a href="#_17">大数据开源软件代码优化</a></li>
</ul>
</li>
<li><a href="#_18">大数据基准测试的应用</a><ul>
<li><a href="#hibench">HiBench</a><ul>
<li><a href="#_19">使用</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_20">前端埋点</a></li>
<li><a href="#_21">常见问题</a><ul>
<li><a href="#_22">网卡是整个系统的瓶颈</a></li>
</ul>
</li>
</ul>
</div>
<h1 id="_1">相关概念</h1>
<h2 id="_2">大数据平台</h2>
<p><img alt="img" src="https://snag.gy/QMIUVC.jpg" /></p>
<h2 id="_3">三驾马车</h2>
<p>分别是分布式文件系统GFS、大数据分布式计算框架MapReduce和NoSQL数据库系统BigTable</p>
<p>即实现了一个文件系统、一个计算框架、一个数据库系统</p>
<h2 id="hdfs">HDFS</h2>
<p>Hadoop File System </p>
<p>HDFS分布式文件存储系统，将文件分成很多块（Block），以块为单位存储在集群的服务器上。</p>
<p>HDFS则是水平伸缩，通过添加更多的服务器实现数据更大、更快、更安全存储与访问。</p>
<p>这些年来，各种计算框架、各种算法、各种应用场景不断推陈出新，让人眼花缭乱，但是大数据存储的王者依然是HDFS。</p>
<h2 id="hadoop">Hadoop</h2>
<p>2006年，Doug Cutting将这些大数据相关的功能从Nutch中分离了出来，然后启动了一个独立的项目专门开发维护大数据技术，这就是后来赫赫有名的Hadoop，主要包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。</p>
<h2 id="pig">Pig</h2>
<p>Yahoo的一些人觉得用MapReduce进行大数据编程太麻烦了，于是便开发了Pig。Pig是一种脚本语言，使用类SQL的语法，开发者可以用Pig脚本描述要对大数据集上进行的操作，Pig经过编译后会生成MapReduce程序，然后在Hadoop上运行。</p>
<h2 id="hive">Hive</h2>
<p>编写Pig脚本虽然比直接MapReduce编程容易，但是依然需要学习新的脚本语法。于是Facebook又发布了Hive。Hive支持使用SQL语法来进行大数据计算，比如说你可以写个Select语句进行数据查询，然后Hive会把SQL语句转化成MapReduce的计算程序。</p>
<p>这样，<strong>熟悉数据库的数据分析师和工程师便可以无门槛地使用大数据进行数据分析和处理了</strong>。Hive出现后极大程度地降低了Hadoop的使用难度</p>
<p>Hive可以在Hadoop上进行SQL操作，实现数据统计与分析。也就是说，<strong>我们可以用更低廉的价格获得比以往多得多的数据存储与计算能力</strong>。可以把运行日志、应用采集数据、数据库数据放到一起进行计算分析，获得以前无法得到的数据结果，企业的数据仓库也随之呈指数级膨胀。</p>
<h2 id="yarn">Yarn 资源调度框架</h2>
<p>在Hadoop早期，MapReduce既是一个执行引擎，又是一个资源调度框架，服务器集群的资源调度管理由MapReduce自己完成。但是这样不利于资源复用，也使得MapReduce非常臃肿。于是一个新项目启动了，将MapReduce执行引擎和资源调度分离开来，这就是Yarn。<strong>2012年，Yarn成为一个独立的项目开始运营，随后被各类大数据产品支持，成为大数据平台上最主流的资源调度系统</strong>。</p>
<h2 id="spark">Spark</h2>
<p>在2012年，UC伯克利AMP实验室（Algorithms、Machine和People的缩写）开发的Spark开始崭露头角。当时AMP实验室的马铁博士发现使用MapReduce进行机器学习计算的时候性能非常差，因为机器学习算法通常需要进行很多次的迭代计算，而MapReduce每执行一次Map和Reduce计算都需要重新启动一次作业，带来大量的无谓消耗。还有一点就是MapReduce主要使用磁盘作为存储介质，而2012年的时候，内存已经突破容量和成本限制，成为数据运行过程中主要的存储介质。Spark一经推出，立即受到业界的追捧，并逐步替代MapReduce在企业应用中的地位。</p>
<h2 id="hbase">HBase</h2>
<p>除了大数据批处理和流处理，NoSQL系统处理的主要也是大规模海量数据的存储与访问，所以也被归为大数据技术。 NoSQL曾经在2011年左右非常火爆，涌现出HBase、Cassandra等许多优秀的产品，其中HBase是从Hadoop中分离出来的、基于HDFS的NoSQL系统。</p>
<h2 id="_4">分布式架构</h2>
<p>分布式架构的原则：尽量使用无状态的服务，不同服务实例之间不共享状态，也就是不持有数据， 主要好处是服务间无需同步状态或者数据，便于扩缩容</p>
<h3 id="_5">框架设计</h3>
<p>框架在架构设计上遵循一个重要的设计原则叫“<strong>依赖倒转原则</strong>”，依赖倒转原则是<strong>高层模块不能依赖低层模块，它们应该共同依赖一个抽象，这个抽象由高层模块定义，由低层模块实现。</strong></p>
<p>所谓高层模块和低层模块的划分，简单说来就是在调用链上，处于前面的是高层，后面的是低层。我们以典型的Java Web应用举例，用户请求在到达服务器以后，最先处理用户请求的是Java Web容器，比如Tomcat、Jetty这些，通过监听80端口，把HTTP二进制流封装成Request对象；然后是Spring MVC框架，把Request对象里的用户参数提取出来，根据请求的URL分发给相应的Model对象处理；再然后就是我们的应用程序，负责处理用户请求，具体来看，还会分成服务层、数据持久层等。</p>
<p>在这个例子中，Tomcat相对于Spring MVC就是高层模块，Spring MVC相对于我们的应用程序也算是高层模块。我们看到虽然Tomcat会调用Spring MVC，因为Tomcat要把Request交给Spring MVC处理，但是Tomcat并没有依赖Spring MVC，Tomcat的代码里不可能有任何一行关于Spring MVC的代码。</p>
<p>Tomcat和Spring MVC都依赖J2EE规范，Spring MVC实现了J2EE规范的HttpServlet抽象类，即DispatcherServlet，并配置在web.xml中。这样，Tomcat就可以调用DispatcherServlet处理用户发来的请求。</p>
<p>同样Spring MVC也不需要依赖我们写的Java代码，而是通过依赖Spring MVC的配置文件或者Annotation这样的抽象，来调用我们的Java代码。</p>
<p>所以，Tomcat或者Spring MVC都可以称作是框架，它们都遵循依赖倒转原则。</p>
<p>实际项目开发中，要做到依赖倒置的方法，一般就是抽象出相应的接口的方法，不依赖具体。面向接口编程。 </p>
<p>更重要的是接口是高层需求的抽象，还是底层实现的抽象。这是依赖倒置的关键，面向接口本身并不能保证依赖倒置原则，否则和接口隔离原则没有区别。</p>
<h2 id="sql">SQL 引擎</h2>
<p>Cloudera开发了Impala，这是一种运行在HDFS上的MPP架构的SQL引擎。和MapReduce启动Map和Reduce两种执行进程，将计算过程分成两个阶段进行计算不同，Impala在所有DataNode服务器上部署相同的Impalad进程，多个Impalad进程相互协作，共同完成SQL计算。在一些统计场景中，Impala可以做到毫秒级的计算速度</p>
<p>Spark出道以后，也迅速推出了自己的SQL引擎Shark，也就是后来的Spark SQL，将SQL语句解析成Spark的执行计划，在Spark上执行。由于Spark比MapReduce快很多，Spark SQL也相应比Hive快很多，并且随着Spark的普及，Spark SQL也逐渐被人们接受。后来Hive推出了Hive on Spark，将Hive的执行计划转换成Spark的计算模型，当然这是后话了。</p>
<p>此外，我们还希望在NoSQL的数据库上执行SQL，毕竟SQL发展了几十年，积累了庞大的用户群体，很多人习惯了用SQL解决问题。于是Saleforce推出了Phoenix，一个执行在HBase上的SQL引擎。</p>
<p>这些SQL引擎基本上都只支持类SQL语法，并不能像数据库那样支持标准SQL，特别是数据仓库领域几乎必然会用到嵌套查询SQL，也就是在where条件里面嵌套select子查询，但是几乎所有的大数据SQL引擎都不支持。</p>
<h1 id="_6">计算类型</h1>
<p>在典型的大数据的业务场景下，数据业务最通用的做法是，采用批处理的技术处理历史全量数据，采用流式计算处理实时新增数据。而像Flink这样的计算引擎，可以同时支持流式计算和批处理计算。</p>
<h2 id="_7">批处理计算/大数据离线计算</h2>
<p>像MapReduce、Spark这类计算框架处理的业务场景都被称作<strong>批处理计算</strong>，因为它们通常针对以“天”为单位产生的数据进行一次计算，然后得到需要的结果，这中间计算需要花费的时间大概是几十分钟甚至更长的时间。因为计算的数据是非在线得到的实时数据，而是历史数据，所以这类计算也被称为<strong>大数据离线计算</strong>。</p>
<h2 id="_8">大数据流计算/大数据实时计算</h2>
<p>而在大数据领域，还有另外一类应用场景，它们需要对实时产生的大量数据进行即时计算，比如对于遍布城市的监控摄像头进行人脸识别和嫌犯追踪。这类计算称为<strong>大数据流计算</strong>，相应地，有Storm、Flink、Spark Streaming等流计算框架来满足此类大数据应用的场景。 流式计算要处理的数据是实时在线产生的数据，所以这类计算也被称为<strong>大数据实时计算</strong>。</p>
<h1 id="_9">应用场景</h1>
<h2 id="_10">数据分析</h2>
<p>主要使用Hive、Spark SQL等SQL引擎完成</p>
<h2 id="_11">数据挖掘与机器学习</h2>
<p>有专门的机器学习框架TensorFlow、Mahout以及MLlib等，内置了主要的机器学习和数据挖掘算法。</p>
<h1 id="_12">大数据计算过程</h1>
<p>1.将待处理的大规模数据存储在服务器集群的所有服务器上，主要使用HDFS分布式文件存储系统，将文件分成很多块（Block），以块为单位存储在集群的服务器上。</p>
<p>2.大数据引擎根据集群里不同服务器的计算能力，在每台服务器上启动若干分布式任务执行进程，这些进程会等待给它们分配执行任务。</p>
<p>3.使用大数据计算框架支持的编程模型进行编程，比如Hadoop的MapReduce编程模型，或者Spark的RDD编程模型。应用程序编写好以后，将其打包，MapReduce和Spark都是在JVM环境中运行，所以打包出来的是一个Java的JAR包。</p>
<p>4.用Hadoop或者Spark的启动命令执行这个应用程序的JAR包，首先执行引擎会解析程序要处理的数据输入路径，根据输入数据量的大小，将数据分成若干片（Split），每一个数据片都分配给一个任务执行进程去处理。</p>
<p>5.任务执行进程收到分配的任务后，检查自己是否有任务对应的程序包，如果没有就去下载程序包，下载以后通过反射的方式加载程序。走到这里，最重要的一步，也就是移动计算就完成了。</p>
<p>6.加载程序后，任务执行进程根据分配的数据片的文件地址和数据在文件内的偏移量读取数据，并把数据输入给应用程序相应的方法去执行，从而实现在分布式服务器集群中移动计算程序，对大规模数据进行并行处理的计算目标。</p>
<h1 id="_13">分布式架构的原则</h1>
<p>尽量使用无状态的服务，不同服务实例之间不共享状态，也就是不持有数据</p>
<p>分布式架构的设计者在考虑架构的可扩展行（伸缩性）的时候设计出来的这样一个针对于服务的一个要求或者是标准（也就是原则）</p>
<p>主要目的是为了实现服务的低耦合高内聚的目标。一旦低耦合高内聚，服务就可以动态伸缩（放/换哪个机器上都可以运行）</p>
<h1 id="_14">大数据软件性能优化</h1>
<p>在大数据使用、开发过程的性能优化一般可以从以下角度着手进行。</p>
<h2 id="sql_1">SQL语句优化</h2>
<p>使用关系数据库的时候，SQL优化是数据库优化的重要手段，因为实现同样功能但是不同的SQL写法可能带来的性能差距是数量级的。我们知道在大数据分析时，由于数据量规模巨大，所以SQL语句写法引起的性能差距就更加巨大。典型的就是Hive的MapJoin语法，如果join的一张表比较小，比如只有几MB，那么就可以用MapJoin进行连接，Hive会将这张小表当作Cache数据全部加载到所有的Map任务中，在Map阶段完成join操作，无需shuffle。</p>
<h2 id="_15">数据倾斜处理</h2>
<p>数据倾斜是指当两张表进行join的时候，其中一张表join的某个字段值对应的数据行数特别多，那么在shuffle的时候，这个字段值（Key）对应的所有记录都会被partition到同一个Reduce任务，导致这个任务长时间无法完成。</p>
<p>淘宝一个案例，把用户日志和用户表通过用户ID进行join，但是日志表有几亿条记录的用户ID是null，Hive把null当作一个字段值shuffle到同一个Reduce，结果这个Reduce跑了两天也没跑完，SQL当然也执行不完。像这种情况的数据倾斜，因为null字段没有意义，所以可以在where条件里加一个userID != null过滤掉就可以了。</p>
<h2 id="mapreducespark">MapReduce、Spark代码优化</h2>
<p>了解MapReduce和Spark的工作原理，了解要处理的数据的特点，了解要计算的目标，设计合理的代码处理逻辑，使用良好的编程方法开发大数据应用，是大数据应用性能优化的重要手段，也大数据开发工程师的重要职责。</p>
<h2 id="_16">配置参数优化</h2>
<p>根据公司数据特点，为部署的大数据产品以及运行的作业选择合适的配置参数，是公司大数据平台性能优化最主要的手段，也是大数据运维工程师的主要职责。比如Yarn的每个Container包含的CPU个数和内存数目、HDFS数据块的大小和复制数等，每个大数据产品都有很多配置参数，这些参数会对大数据运行时的性能产生重要影响。</p>
<h2 id="_17">大数据开源软件代码优化</h2>
<p>修改直接修改Hadoop、Spark、Sqoop这些产品的代码进行性能优化的方法虽然比较激进，但是对于掌控自己公司的大数据平台来说，效果可能是最好的。</p>
<h1 id="_18">大数据基准测试的应用</h1>
<p>大数据基准测试的主要用途是对各种大数据产品进行测试，检验大数据产品在不同硬件平台、不同数据量、不同计算任务下的性能表现</p>
<h2 id="hibench">HiBench</h2>
<p>大数据基准测试工具HiBench</p>
<p>HiBench内置了若干主要的大数据计算程序作为基准测试的负载（workload）。</p>
<ul>
<li>Sort，对数据进行排序大数据程序。</li>
<li>WordCount，前面多次提到过，词频统计大数据计算程序。</li>
<li>TeraSort，对1TB数据进行排序，最早是一项关于软件和硬件的计算力的竞赛，所以很多大数据平台和硬件厂商进行产品宣传的时候会用TeraSort成绩作为卖点。</li>
<li>Bayes分类，机器学习分类算法，用于数据分类和预测。</li>
<li>k-means聚类，对数据集合规律进行挖掘的算法。</li>
<li>逻辑回归，数据进行预测和回归的算法。</li>
<li>SQL，包括全表扫描、聚合操作（group by）、连接操作（join）几种典型查询SQL。</li>
<li>PageRank，Web排序算法。</li>
</ul>
<p>此外还有十几种常用大数据计算程序，支持的大数据框架包括MapReduce、Spark、Storm等。</p>
<p>HiBench的价值不在于对各种大数据系统进行基准测试，而是学习大数据、验证自己大数据平台性能的工具。</p>
<h3 id="_19">使用</h3>
<p>HiBench使用非常简单，只需要三步：</p>
<p>1.配置，配置要测试的数据量、大数据运行环境和路径信息等基本参数。</p>
<p>2.初始化数据，生成准备要计算的数据，比如要测试1TB数据的排序，那么就生成1TB数据。</p>
<p>3.执行测试，运行对应的大数据计算程序。</p>
<p>具体初始化和执行命令也非常简单，比如要生成数据，只需要运行bin目录下对应workload的prepare.sh就可以自动生成配置大小的数据。</p>
<div class="hlcode"><pre><span class="n">bin</span><span class="o">/</span><span class="n">workloads</span><span class="o">/</span><span class="n">micro</span><span class="o">/</span><span class="n">terasort</span><span class="o">/</span><span class="n">prepare</span><span class="o">/</span><span class="n">prepare</span><span class="p">.</span><span class="n">sh</span>
</pre></div>


<p>要执行大数据计算，运行run.sh就可以了。</p>
<div class="hlcode"><pre><span class="n">bin</span><span class="o">/</span><span class="n">workloads</span><span class="o">/</span><span class="n">micro</span><span class="o">/</span><span class="n">terasort</span><span class="o">/</span><span class="n">hadoop</span><span class="o">/</span><span class="n">run</span><span class="p">.</span><span class="n">sh</span>
<span class="n">bin</span><span class="o">/</span><span class="n">workloads</span><span class="o">/</span><span class="n">micro</span><span class="o">/</span><span class="n">terasort</span><span class="o">/</span><span class="n">spark</span><span class="o">/</span><span class="n">run</span><span class="p">.</span><span class="n">sh</span>
</pre></div>


<h1 id="_20">前端埋点</h1>
<p>前端埋点数据采集也是互联网应用大数据的重要来源之一，用户的某些前端行为并不会产生后端请求，比如用户在一个页面的停留时间、用户拖动页面的速度、用户选中一个复选框然后又取消了。这些信息对于大数据处理，对于分析用户行为，进行智能推荐都很有价值。但是这些数据必须通过前端埋点获得，所谓前端埋点，就是应用前端为了进行数据统计和分析而采集数据。</p>
<p>埋点的方式主要有手工埋点和自动化埋点。</p>
<p>手工埋点就是前端开发者手动编程将需要采集的前端数据发送到后端的数据采集系统。通常公司会开发一些前端数据上报的SDK，前端工程师在需要埋点的地方，调用SDK，按照接口规范传入相关参数，比如ID、名称、页面、控件等通用参数，还有业务逻辑数据等，SDK将这些数据通过HTTP的方式发送到后端服务器。</p>
<p>自动化埋点则是通过一个前端程序SDK，自动收集全部用户操作事件，然后全量上传到后端服器。自动化埋点有时候也被称作无埋点，意思是无需埋点，实际上是全埋点，即全部用户操作都埋点采集。自动化埋点的好处是开发工作量小，数据规范统一。缺点是采集的数据量大，很多数据采集来也不知道有什么用，白白浪费了计算资源，特别是对于流量敏感的移动端用户而言，因为自动化埋点采集上传花费了大量的流量，可能因此成为卸载应用的理由，这样就得不偿失了。在实践中，有时候只是针对部分用户做自动埋点，抽样一部分数据做统计分析。</p>
<p>介于手工埋点和自动化埋点之间的，还有一种方案是可视化埋点。通过可视化的方式配置哪些前端操作需要埋点，根据配置采集数据。可视化埋点实际上是可以人工干预的自动化埋点。</p>
<h1 id="_21">常见问题</h1>
<h2 id="_22">网卡是整个系统的瓶颈</h2>
<p>程序运行过程中网卡达到了最大I/O能力，整个系统经常在等待网卡的数据传输，请问，你有什么性能优化建议呢？</p>
<p>如果是网络问题，可以考虑batch要发送的网络包，打包一起发送。另一个能想到的就是compression. </p>
<p>确定问题细节原因，针对主要问题进行解决<br />
1.如是网卡接入能力不够，则需要更换网卡或增加网卡<br />
2.如是网卡--应用之间的io瓶颈，则需要考虑零拷贝减少copy释放性能，使用大页内存减少页表miss，使用专门核心做收包缓存到软队列等</p>
<p>采用netty这样的网络框架，因为netty的数据读写都是在bytebuf中进行的。而且我们可以自定义channelHandler在数据出站入站的时候编解码，压缩解压。</p>
<p>1.批量发送数据<br />
2.压缩传输数据<br />
3.增加带宽</p>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2019 Xu XueHua.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2019-08-01 11:33:06</p>
      </span>
    </div>

    
    
  </body>
</html>
<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/static/css/tango.css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>basic_knowledge - Xu XueHua</title>
    <meta name="keywords" content="Xu XueHua"/>
    <meta name="description" content="Xu XueHua's public notes"/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
    <div id="container">
      
<div id="header">
  <div class="post-nav"><a href="/">Home</a>&nbsp;&#187;&nbsp;<a href="/#Big_data">Big_data</a>&nbsp;&#187;&nbsp;basic_knowledge
    <span class="updated">Page Updated&nbsp;
      2019-06-11 21:51
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">basic_knowledge</div>

  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">相关概念</a><ul>
<li><a href="#_2">大数据平台</a></li>
<li><a href="#_3">三驾马车</a></li>
<li><a href="#hdfs">HDFS</a></li>
<li><a href="#hadoop">Hadoop</a></li>
<li><a href="#pig">Pig</a></li>
<li><a href="#hive">Hive</a></li>
<li><a href="#yarn">Yarn 资源调度框架</a></li>
<li><a href="#spark">Spark</a></li>
<li><a href="#hbase">HBase</a></li>
<li><a href="#_4">分布式架构</a><ul>
<li><a href="#_5">框架设计</a></li>
</ul>
</li>
<li><a href="#sql">SQL 引擎</a></li>
</ul>
</li>
<li><a href="#_6">计算类型</a><ul>
<li><a href="#_7">批处理计算/大数据离线计算</a></li>
<li><a href="#_8">大数据流计算/大数据实时计算</a></li>
</ul>
</li>
<li><a href="#_9">应用场景</a><ul>
<li><a href="#_10">数据分析</a></li>
<li><a href="#_11">数据挖掘与机器学习</a></li>
</ul>
</li>
<li><a href="#_12">大数据计算过程</a></li>
<li><a href="#_13">分布式架构的原则</a></li>
</ul>
</div>
<h1 id="_1">相关概念</h1>
<h2 id="_2">大数据平台</h2>
<p><img alt="img" src="https://snag.gy/QMIUVC.jpg" /></p>
<h2 id="_3">三驾马车</h2>
<p>分别是分布式文件系统GFS、大数据分布式计算框架MapReduce和NoSQL数据库系统BigTable</p>
<p>即实现了一个文件系统、一个计算框架、一个数据库系统</p>
<h2 id="hdfs">HDFS</h2>
<p>Hadoop File System </p>
<p>HDFS分布式文件存储系统，将文件分成很多块（Block），以块为单位存储在集群的服务器上。</p>
<p>HDFS则是水平伸缩，通过添加更多的服务器实现数据更大、更快、更安全存储与访问。</p>
<p>这些年来，各种计算框架、各种算法、各种应用场景不断推陈出新，让人眼花缭乱，但是大数据存储的王者依然是HDFS。</p>
<h2 id="hadoop">Hadoop</h2>
<p>2006年，Doug Cutting将这些大数据相关的功能从Nutch中分离了出来，然后启动了一个独立的项目专门开发维护大数据技术，这就是后来赫赫有名的Hadoop，主要包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。</p>
<h2 id="pig">Pig</h2>
<p>Yahoo的一些人觉得用MapReduce进行大数据编程太麻烦了，于是便开发了Pig。Pig是一种脚本语言，使用类SQL的语法，开发者可以用Pig脚本描述要对大数据集上进行的操作，Pig经过编译后会生成MapReduce程序，然后在Hadoop上运行。</p>
<h2 id="hive">Hive</h2>
<p>编写Pig脚本虽然比直接MapReduce编程容易，但是依然需要学习新的脚本语法。于是Facebook又发布了Hive。Hive支持使用SQL语法来进行大数据计算，比如说你可以写个Select语句进行数据查询，然后Hive会把SQL语句转化成MapReduce的计算程序。</p>
<p>这样，<strong>熟悉数据库的数据分析师和工程师便可以无门槛地使用大数据进行数据分析和处理了</strong>。Hive出现后极大程度地降低了Hadoop的使用难度</p>
<p>Hive可以在Hadoop上进行SQL操作，实现数据统计与分析。也就是说，<strong>我们可以用更低廉的价格获得比以往多得多的数据存储与计算能力</strong>。可以把运行日志、应用采集数据、数据库数据放到一起进行计算分析，获得以前无法得到的数据结果，企业的数据仓库也随之呈指数级膨胀。</p>
<h2 id="yarn">Yarn 资源调度框架</h2>
<p>在Hadoop早期，MapReduce既是一个执行引擎，又是一个资源调度框架，服务器集群的资源调度管理由MapReduce自己完成。但是这样不利于资源复用，也使得MapReduce非常臃肿。于是一个新项目启动了，将MapReduce执行引擎和资源调度分离开来，这就是Yarn。<strong>2012年，Yarn成为一个独立的项目开始运营，随后被各类大数据产品支持，成为大数据平台上最主流的资源调度系统</strong>。</p>
<h2 id="spark">Spark</h2>
<p>在2012年，UC伯克利AMP实验室（Algorithms、Machine和People的缩写）开发的Spark开始崭露头角。当时AMP实验室的马铁博士发现使用MapReduce进行机器学习计算的时候性能非常差，因为机器学习算法通常需要进行很多次的迭代计算，而MapReduce每执行一次Map和Reduce计算都需要重新启动一次作业，带来大量的无谓消耗。还有一点就是MapReduce主要使用磁盘作为存储介质，而2012年的时候，内存已经突破容量和成本限制，成为数据运行过程中主要的存储介质。Spark一经推出，立即受到业界的追捧，并逐步替代MapReduce在企业应用中的地位。</p>
<h2 id="hbase">HBase</h2>
<p>除了大数据批处理和流处理，NoSQL系统处理的主要也是大规模海量数据的存储与访问，所以也被归为大数据技术。 NoSQL曾经在2011年左右非常火爆，涌现出HBase、Cassandra等许多优秀的产品，其中HBase是从Hadoop中分离出来的、基于HDFS的NoSQL系统。</p>
<h2 id="_4">分布式架构</h2>
<p>分布式架构的原则：尽量使用无状态的服务，不同服务实例之间不共享状态，也就是不持有数据， 主要好处是服务间无需同步状态或者数据，便于扩缩容</p>
<h3 id="_5">框架设计</h3>
<p>框架在架构设计上遵循一个重要的设计原则叫“<strong>依赖倒转原则</strong>”，依赖倒转原则是<strong>高层模块不能依赖低层模块，它们应该共同依赖一个抽象，这个抽象由高层模块定义，由低层模块实现。</strong></p>
<p>所谓高层模块和低层模块的划分，简单说来就是在调用链上，处于前面的是高层，后面的是低层。我们以典型的Java Web应用举例，用户请求在到达服务器以后，最先处理用户请求的是Java Web容器，比如Tomcat、Jetty这些，通过监听80端口，把HTTP二进制流封装成Request对象；然后是Spring MVC框架，把Request对象里的用户参数提取出来，根据请求的URL分发给相应的Model对象处理；再然后就是我们的应用程序，负责处理用户请求，具体来看，还会分成服务层、数据持久层等。</p>
<p>在这个例子中，Tomcat相对于Spring MVC就是高层模块，Spring MVC相对于我们的应用程序也算是高层模块。我们看到虽然Tomcat会调用Spring MVC，因为Tomcat要把Request交给Spring MVC处理，但是Tomcat并没有依赖Spring MVC，Tomcat的代码里不可能有任何一行关于Spring MVC的代码。</p>
<p>Tomcat和Spring MVC都依赖J2EE规范，Spring MVC实现了J2EE规范的HttpServlet抽象类，即DispatcherServlet，并配置在web.xml中。这样，Tomcat就可以调用DispatcherServlet处理用户发来的请求。</p>
<p>同样Spring MVC也不需要依赖我们写的Java代码，而是通过依赖Spring MVC的配置文件或者Annotation这样的抽象，来调用我们的Java代码。</p>
<p>所以，Tomcat或者Spring MVC都可以称作是框架，它们都遵循依赖倒转原则。</p>
<p>实际项目开发中，要做到依赖倒置的方法，一般就是抽象出相应的接口的方法，不依赖具体。面向接口编程。 </p>
<p>更重要的是接口是高层需求的抽象，还是底层实现的抽象。这是依赖倒置的关键，面向接口本身并不能保证依赖倒置原则，否则和接口隔离原则没有区别。</p>
<h2 id="sql">SQL 引擎</h2>
<p>Cloudera开发了Impala，这是一种运行在HDFS上的MPP架构的SQL引擎。和MapReduce启动Map和Reduce两种执行进程，将计算过程分成两个阶段进行计算不同，Impala在所有DataNode服务器上部署相同的Impalad进程，多个Impalad进程相互协作，共同完成SQL计算。在一些统计场景中，Impala可以做到毫秒级的计算速度</p>
<p>Spark出道以后，也迅速推出了自己的SQL引擎Shark，也就是后来的Spark SQL，将SQL语句解析成Spark的执行计划，在Spark上执行。由于Spark比MapReduce快很多，Spark SQL也相应比Hive快很多，并且随着Spark的普及，Spark SQL也逐渐被人们接受。后来Hive推出了Hive on Spark，将Hive的执行计划转换成Spark的计算模型，当然这是后话了。</p>
<p>此外，我们还希望在NoSQL的数据库上执行SQL，毕竟SQL发展了几十年，积累了庞大的用户群体，很多人习惯了用SQL解决问题。于是Saleforce推出了Phoenix，一个执行在HBase上的SQL引擎。</p>
<p>这些SQL引擎基本上都只支持类SQL语法，并不能像数据库那样支持标准SQL，特别是数据仓库领域几乎必然会用到嵌套查询SQL，也就是在where条件里面嵌套select子查询，但是几乎所有的大数据SQL引擎都不支持。</p>
<h1 id="_6">计算类型</h1>
<p>在典型的大数据的业务场景下，数据业务最通用的做法是，采用批处理的技术处理历史全量数据，采用流式计算处理实时新增数据。而像Flink这样的计算引擎，可以同时支持流式计算和批处理计算。</p>
<h2 id="_7">批处理计算/大数据离线计算</h2>
<p>像MapReduce、Spark这类计算框架处理的业务场景都被称作<strong>批处理计算</strong>，因为它们通常针对以“天”为单位产生的数据进行一次计算，然后得到需要的结果，这中间计算需要花费的时间大概是几十分钟甚至更长的时间。因为计算的数据是非在线得到的实时数据，而是历史数据，所以这类计算也被称为<strong>大数据离线计算</strong>。</p>
<h2 id="_8">大数据流计算/大数据实时计算</h2>
<p>而在大数据领域，还有另外一类应用场景，它们需要对实时产生的大量数据进行即时计算，比如对于遍布城市的监控摄像头进行人脸识别和嫌犯追踪。这类计算称为<strong>大数据流计算</strong>，相应地，有Storm、Flink、Spark Streaming等流计算框架来满足此类大数据应用的场景。 流式计算要处理的数据是实时在线产生的数据，所以这类计算也被称为<strong>大数据实时计算</strong>。</p>
<h1 id="_9">应用场景</h1>
<h2 id="_10">数据分析</h2>
<p>主要使用Hive、Spark SQL等SQL引擎完成</p>
<h2 id="_11">数据挖掘与机器学习</h2>
<p>有专门的机器学习框架TensorFlow、Mahout以及MLlib等，内置了主要的机器学习和数据挖掘算法。</p>
<h1 id="_12">大数据计算过程</h1>
<p>1.将待处理的大规模数据存储在服务器集群的所有服务器上，主要使用HDFS分布式文件存储系统，将文件分成很多块（Block），以块为单位存储在集群的服务器上。</p>
<p>2.大数据引擎根据集群里不同服务器的计算能力，在每台服务器上启动若干分布式任务执行进程，这些进程会等待给它们分配执行任务。</p>
<p>3.使用大数据计算框架支持的编程模型进行编程，比如Hadoop的MapReduce编程模型，或者Spark的RDD编程模型。应用程序编写好以后，将其打包，MapReduce和Spark都是在JVM环境中运行，所以打包出来的是一个Java的JAR包。</p>
<p>4.用Hadoop或者Spark的启动命令执行这个应用程序的JAR包，首先执行引擎会解析程序要处理的数据输入路径，根据输入数据量的大小，将数据分成若干片（Split），每一个数据片都分配给一个任务执行进程去处理。</p>
<p>5.任务执行进程收到分配的任务后，检查自己是否有任务对应的程序包，如果没有就去下载程序包，下载以后通过反射的方式加载程序。走到这里，最重要的一步，也就是移动计算就完成了。</p>
<p>6.加载程序后，任务执行进程根据分配的数据片的文件地址和数据在文件内的偏移量读取数据，并把数据输入给应用程序相应的方法去执行，从而实现在分布式服务器集群中移动计算程序，对大规模数据进行并行处理的计算目标。</p>
<h1 id="_13">分布式架构的原则</h1>
<p>尽量使用无状态的服务，不同服务实例之间不共享状态，也就是不持有数据</p>
<p>分布式架构的设计者在考虑架构的可扩展行（伸缩性）的时候设计出来的这样一个针对于服务的一个要求或者是标准（也就是原则）</p>
<p>主要目的是为了实现服务的低耦合高内聚的目标。一旦低耦合高内聚，服务就可以动态伸缩（放/换哪个机器上都可以运行）</p>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2019 Xu XueHua.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2019-07-16 14:47:29</p>
      </span>
    </div>

    
    
  </body>
</html>
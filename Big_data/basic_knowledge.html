<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/static/css/tango.css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>basic_knowledge - Xu XueHua</title>
    <meta name="keywords" content="Xu XueHua"/>
    <meta name="description" content="Xu XueHua's public notes"/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
    <div id="container">
      
<div id="header">
  <div class="post-nav"><a href="/">Home</a>&nbsp;&#187;&nbsp;<a href="/#Big_data">Big_data</a>&nbsp;&#187;&nbsp;basic_knowledge
    <span class="updated">Page Updated&nbsp;
      2019-06-11 21:51
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">basic_knowledge</div>

  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">相关概念</a><ul>
<li><a href="#_2">大数据平台</a></li>
<li><a href="#_3">三驾马车</a></li>
<li><a href="#hdfs">HDFS</a></li>
<li><a href="#hadoop">Hadoop</a></li>
<li><a href="#pig">Pig</a></li>
<li><a href="#hive">Hive</a></li>
<li><a href="#yarn">Yarn 资源调度框架</a></li>
<li><a href="#spark">Spark</a></li>
<li><a href="#hbase">HBase</a></li>
</ul>
</li>
<li><a href="#_4">计算类型</a><ul>
<li><a href="#_5">批处理计算/大数据离线计算</a></li>
<li><a href="#_6">大数据流计算/大数据实时计算</a></li>
</ul>
</li>
<li><a href="#_7">应用场景</a><ul>
<li><a href="#_8">数据分析</a></li>
<li><a href="#_9">数据挖掘与机器学习</a></li>
</ul>
</li>
<li><a href="#_10">大数据计算过程</a></li>
<li><a href="#_11">分布式架构的原则</a></li>
</ul>
</div>
<h1 id="_1">相关概念</h1>
<h2 id="_2">大数据平台</h2>
<p><img alt="img" src="https://snag.gy/QMIUVC.jpg" /></p>
<h2 id="_3">三驾马车</h2>
<p>分别是分布式文件系统GFS、大数据分布式计算框架MapReduce和NoSQL数据库系统BigTable</p>
<p>即实现了一个文件系统、一个计算框架、一个数据库系统</p>
<h2 id="hdfs">HDFS</h2>
<p>Hadoop File System </p>
<p>HDFS分布式文件存储系统，将文件分成很多块（Block），以块为单位存储在集群的服务器上。</p>
<p>HDFS则是水平伸缩，通过添加更多的服务器实现数据更大、更快、更安全存储与访问。</p>
<p>这些年来，各种计算框架、各种算法、各种应用场景不断推陈出新，让人眼花缭乱，但是大数据存储的王者依然是HDFS。</p>
<h2 id="hadoop">Hadoop</h2>
<p>2006年，Doug Cutting将这些大数据相关的功能从Nutch中分离了出来，然后启动了一个独立的项目专门开发维护大数据技术，这就是后来赫赫有名的Hadoop，主要包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。</p>
<h2 id="pig">Pig</h2>
<p>Yahoo的一些人觉得用MapReduce进行大数据编程太麻烦了，于是便开发了Pig。Pig是一种脚本语言，使用类SQL的语法，开发者可以用Pig脚本描述要对大数据集上进行的操作，Pig经过编译后会生成MapReduce程序，然后在Hadoop上运行。</p>
<h2 id="hive">Hive</h2>
<p>编写Pig脚本虽然比直接MapReduce编程容易，但是依然需要学习新的脚本语法。于是Facebook又发布了Hive。Hive支持使用SQL语法来进行大数据计算，比如说你可以写个Select语句进行数据查询，然后Hive会把SQL语句转化成MapReduce的计算程序。</p>
<p>这样，<strong>熟悉数据库的数据分析师和工程师便可以无门槛地使用大数据进行数据分析和处理了</strong>。Hive出现后极大程度地降低了Hadoop的使用难度</p>
<p>Hive可以在Hadoop上进行SQL操作，实现数据统计与分析。也就是说，<strong>我们可以用更低廉的价格获得比以往多得多的数据存储与计算能力</strong>。可以把运行日志、应用采集数据、数据库数据放到一起进行计算分析，获得以前无法得到的数据结果，企业的数据仓库也随之呈指数级膨胀。</p>
<h2 id="yarn">Yarn 资源调度框架</h2>
<p>在Hadoop早期，MapReduce既是一个执行引擎，又是一个资源调度框架，服务器集群的资源调度管理由MapReduce自己完成。但是这样不利于资源复用，也使得MapReduce非常臃肿。于是一个新项目启动了，将MapReduce执行引擎和资源调度分离开来，这就是Yarn。<strong>2012年，Yarn成为一个独立的项目开始运营，随后被各类大数据产品支持，成为大数据平台上最主流的资源调度系统</strong>。</p>
<h2 id="spark">Spark</h2>
<p>在2012年，UC伯克利AMP实验室（Algorithms、Machine和People的缩写）开发的Spark开始崭露头角。当时AMP实验室的马铁博士发现使用MapReduce进行机器学习计算的时候性能非常差，因为机器学习算法通常需要进行很多次的迭代计算，而MapReduce每执行一次Map和Reduce计算都需要重新启动一次作业，带来大量的无谓消耗。还有一点就是MapReduce主要使用磁盘作为存储介质，而2012年的时候，内存已经突破容量和成本限制，成为数据运行过程中主要的存储介质。Spark一经推出，立即受到业界的追捧，并逐步替代MapReduce在企业应用中的地位。</p>
<h2 id="hbase">HBase</h2>
<p>除了大数据批处理和流处理，NoSQL系统处理的主要也是大规模海量数据的存储与访问，所以也被归为大数据技术。 NoSQL曾经在2011年左右非常火爆，涌现出HBase、Cassandra等许多优秀的产品，其中HBase是从Hadoop中分离出来的、基于HDFS的NoSQL系统。</p>
<h1 id="_4">计算类型</h1>
<p>在典型的大数据的业务场景下，数据业务最通用的做法是，采用批处理的技术处理历史全量数据，采用流式计算处理实时新增数据。而像Flink这样的计算引擎，可以同时支持流式计算和批处理计算。</p>
<h2 id="_5">批处理计算/大数据离线计算</h2>
<p>像MapReduce、Spark这类计算框架处理的业务场景都被称作<strong>批处理计算</strong>，因为它们通常针对以“天”为单位产生的数据进行一次计算，然后得到需要的结果，这中间计算需要花费的时间大概是几十分钟甚至更长的时间。因为计算的数据是非在线得到的实时数据，而是历史数据，所以这类计算也被称为<strong>大数据离线计算</strong>。</p>
<h2 id="_6">大数据流计算/大数据实时计算</h2>
<p>而在大数据领域，还有另外一类应用场景，它们需要对实时产生的大量数据进行即时计算，比如对于遍布城市的监控摄像头进行人脸识别和嫌犯追踪。这类计算称为<strong>大数据流计算</strong>，相应地，有Storm、Flink、Spark Streaming等流计算框架来满足此类大数据应用的场景。 流式计算要处理的数据是实时在线产生的数据，所以这类计算也被称为<strong>大数据实时计算</strong>。</p>
<h1 id="_7">应用场景</h1>
<h2 id="_8">数据分析</h2>
<p>主要使用Hive、Spark SQL等SQL引擎完成</p>
<h2 id="_9">数据挖掘与机器学习</h2>
<p>有专门的机器学习框架TensorFlow、Mahout以及MLlib等，内置了主要的机器学习和数据挖掘算法。</p>
<h1 id="_10">大数据计算过程</h1>
<p>1.将待处理的大规模数据存储在服务器集群的所有服务器上，主要使用HDFS分布式文件存储系统，将文件分成很多块（Block），以块为单位存储在集群的服务器上。</p>
<p>2.大数据引擎根据集群里不同服务器的计算能力，在每台服务器上启动若干分布式任务执行进程，这些进程会等待给它们分配执行任务。</p>
<p>3.使用大数据计算框架支持的编程模型进行编程，比如Hadoop的MapReduce编程模型，或者Spark的RDD编程模型。应用程序编写好以后，将其打包，MapReduce和Spark都是在JVM环境中运行，所以打包出来的是一个Java的JAR包。</p>
<p>4.用Hadoop或者Spark的启动命令执行这个应用程序的JAR包，首先执行引擎会解析程序要处理的数据输入路径，根据输入数据量的大小，将数据分成若干片（Split），每一个数据片都分配给一个任务执行进程去处理。</p>
<p>5.任务执行进程收到分配的任务后，检查自己是否有任务对应的程序包，如果没有就去下载程序包，下载以后通过反射的方式加载程序。走到这里，最重要的一步，也就是移动计算就完成了。</p>
<p>6.加载程序后，任务执行进程根据分配的数据片的文件地址和数据在文件内的偏移量读取数据，并把数据输入给应用程序相应的方法去执行，从而实现在分布式服务器集群中移动计算程序，对大规模数据进行并行处理的计算目标。</p>
<h1 id="_11">分布式架构的原则</h1>
<p>尽量使用无状态的服务，不同服务实例之间不共享状态，也就是不持有数据</p>
<p>分布式架构的设计者在考虑架构的可扩展行（伸缩性）的时候设计出来的这样一个针对于服务的一个要求或者是标准（也就是原则）</p>
<p>主要目的是为了实现服务的低耦合高内聚的目标。一旦低耦合高内聚，服务就可以动态伸缩（放/换哪个机器上都可以运行）</p>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2019 Xu XueHua.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2019-06-24 20:58:46</p>
      </span>
    </div>

    
    
  </body>
</html>
<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/static/css/tango.css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>k8s_in_aws - Xu XueHua</title>
    <meta name="keywords" content="Xu XueHua"/>
    <meta name="description" content="Xu XueHua's public notes"/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
    <div id="container">
      
<div id="header">
  <div class="post-nav"><a href="/">Home</a>&nbsp;&#187;&nbsp;<a href="/#Kubernetes">Kubernetes</a>&nbsp;&#187;&nbsp;k8s_in_aws
    <span class="updated">Page Updated&nbsp;
      2019-03-05 11:28
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">k8s_in_aws</div>

  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#eks">EKS</a><ul>
<li><a href="#iam-configuration">IAM configuration</a><ul>
<li><a href="#policies">Policies</a></li>
<li><a href="#roles">Roles</a></li>
<li><a href="#users">Users</a></li>
</ul>
</li>
<li><a href="#vpc-created-for-eks-use">VPC created for EKS use</a></li>
<li><a href="#install-kubectl-for-eks-auth">Install kubectl for EKS auth</a><ul>
<li><a href="#kubectl">kubectl</a></li>
<li><a href="#aws-iam-authenticator">aws-iam-authenticator</a></li>
<li><a href="#aws-cli">AWS CLI</a></li>
</ul>
</li>
<li><a href="#create-cluster-control-plane">Create cluster control plane</a></li>
<li><a href="#create-worker-nodes">Create worker nodes</a></li>
<li><a href="#scale-policy">Scale policy</a></li>
<li><a href="#label-the-nodes">Label the nodes</a></li>
<li><a href="#create-an-elb">create an ELB</a><ul>
<li><a href="#mapping-storage">Mapping storage</a></li>
<li><a href="#clean-up-the-storage">Clean up the storage</a></li>
</ul>
</li>
<li><a href="#networking">Networking</a><ul>
<li><a href="#ingress">Ingress</a></li>
<li><a href="#network-policy-with-callco">Network Policy with Callco</a></li>
</ul>
</li>
<li><a href="#adding-users">Adding Users</a></li>
<li><a href="#install_prometheus">Install_Prometheus</a></li>
</ul>
</li>
</ul>
</div>
<h1 id="eks">EKS</h1>
<p>Kubernetes on AWS</p>
<p><img alt="img" src="https://snag.gy/FPMuN5.jpg" /></p>
<h2 id="iam-configuration">IAM configuration</h2>
<h3 id="policies">Policies</h3>
<p>In order to access the EKS cluster services an IAM policy is needed.  The following, while "open" only allows eks service access, and is appropriate for most users who need to manipulate the EKS service.</p>
<p>https://console.aws.amazon.com/iam/<br />
Create a Policy with the following JSON object, and name it AdminEKSPolicy</p>
<p>iam_eks_policy.json</p>
<div class="hlcode"><pre><span class="p">{</span>
    <span class="s2">&quot;Version&quot;</span><span class="o">:</span> <span class="s2">&quot;2012-10-17&quot;</span><span class="o">,</span>
    <span class="s2">&quot;Statement&quot;</span><span class="o">:</span> <span class="cp">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;Effect&quot;</span><span class="p">:</span> <span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Action&quot;</span><span class="p">:</span> <span class="err">[</span>
                <span class="s2">&quot;eks:*&quot;</span>
            <span class="cp">]</span><span class="o">,</span>
            <span class="s2">&quot;Resource&quot;</span><span class="o">:</span> <span class="s2">&quot;*&quot;</span>
        <span class="p">}</span>
    <span class="o">]</span>
<span class="err">}</span>
</pre></div>


<p>We also need CloudFormation access which we can call AdminCloudFormationPolicy<br />
iam_cf_policy.json</p>
<div class="hlcode"><pre><span class="p">{</span>
    <span class="s2">&quot;Version&quot;</span><span class="o">:</span> <span class="s2">&quot;2012-10-17&quot;</span><span class="o">,</span>
    <span class="s2">&quot;Statement&quot;</span><span class="o">:</span> <span class="cp">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;Effect&quot;</span><span class="p">:</span> <span class="s2">&quot;Allow&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Action&quot;</span><span class="p">:</span> <span class="s2">&quot;*&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Resource&quot;</span><span class="p">:</span> <span class="s2">&quot;*&quot;</span>
        <span class="p">}</span>
    <span class="cp">]</span>
<span class="p">}</span>
</pre></div>


<h3 id="roles">Roles</h3>
<p>Create and then select <code>AWS service</code> , <code>ESK</code></p>
<p>Click next until the <code>Role name</code> with <code>ClusterEksRole</code></p>
<p>This will have two Amazon defined policies:</p>
<p>AmazonEKSServicePolicy <br />
AmazonEKSClusterPolicy </p>
<p>View the role in details and copy <code>Role ARN</code></p>
<h3 id="users">Users</h3>
<p>create two users, an admin user and a second eks system user.</p>
<p>User 1:<br />
 clusterAdmin </p>
<ul>
<li>eks admin policy</li>
<li>k8s admin "system:master" group<br />
   the following policies (at Review section):<br />
   AdminEKSPolicy<br />
   AdminCloudFormationPolicy<br />
   AmazonEKSServicePolicy <br />
   AmazonEKSClusterPolicy </li>
</ul>
<p>User 2:<br />
 clusterUser</p>
<ul>
<li>
<p>no IAM policies</p>
</li>
<li>
<p>k8s admin "system:master" group</p>
</li>
</ul>
<p>the following policies (at Review section):</p>
<p>â€‹       AdminEKSPolicy</p>
<p>For both users, create programmatic credentials, and for the admin user, create a password credential as well.</p>
<h2 id="vpc-created-for-eks-use">VPC created for EKS use</h2>
<p>Signout and login as clusterAdmin user with below regions</p>
<p>EKS is only supported in three regions:<br />
us-east-1 (Northern VA)<br />
us-west-2 (Oregon)<br />
eu-west-1 (Ireland)</p>
<p>Make sure you are in one of those regions when launching your VPC template</p>
<p>https://console.aws.amazon.com/cloudformation/</p>
<p>Then <code>Create Stack</code>  and specify below template</p>
<p>From S3 template<br />
https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-vpc-sample.yaml</p>
<p>and specify the stack name <code>classEKSVPS</code></p>
<p>Capture (into an outputs file):<br />
VPC-ID:<br />
SECURITY-GROUP-ID:<br />
SUBNET-IDS:</p>
<p>So EKS will deploy into this specific region which not impact other env.</p>
<h2 id="install-kubectl-for-eks-auth">Install kubectl for EKS auth</h2>
<h3 id="kubectl">kubectl</h3>
<p>Install kubectl as normal from the instructions found here:<br />
https://kubernetes.io/docs/tasks/tools/install-kubectl/</p>
<p>Linux:<br />
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl</p>
<p>MacOS:<br />
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl</p>
<p>Windows:<br />
curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.12.0/bin/windows/amd64/kubectl.exe</p>
<h3 id="aws-iam-authenticator">aws-iam-authenticator</h3>
<p>We also need the aws-iam-authenticator binary:<br />
https://docs.aws.amazon.com/eks/latest/userguide/configure-kubectl.html</p>
<p>You need the binary appropriate to your OS:<br />
Linux:<br />
curl -sLO https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/linux/amd64/aws-iam-authenticator</p>
<p>MacOS:<br />
curl -sLO https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/darwin/amd64/aws-iam-authenticator</p>
<p>Windows:<br />
curl -sLO https://amazon-eks.s3-us-west-2.amazonaws.com/1.10.3/2018-07-26/bin/windows/amd64/aws-iam-authenticator.exe</p>
<p>In both cases, make the binary executable if necessary (chmod +x), and copy it to a directory in the command PATH (/usr/local/bin or %system32%/)</p>
<h3 id="aws-cli">AWS CLI</h3>
<div class="hlcode"><pre><span class="n">curl</span> <span class="s">&quot;https://s3.amazonaws.com/aws-cli/awscli-bundle.zip&quot;</span> <span class="o">-</span><span class="n">o</span> <span class="s">&quot;awscli-bundle.zip&quot;</span> <span class="o">&amp;&amp;</span> <span class="err">\</span> <span class="n">unzip</span> <span class="n">awscli</span><span class="o">-</span><span class="n">bundle</span><span class="p">.</span><span class="n">zip</span> <span class="o">&amp;&amp;</span> \
<span class="n">cd</span> <span class="n">awscli</span><span class="o">-</span><span class="n">bundle</span> <span class="o">&amp;&amp;</span> \
<span class="n">sudo</span> <span class="p">.</span><span class="o">/</span><span class="n">awscli</span><span class="o">-</span><span class="n">bundle</span><span class="o">/</span><span class="n">install</span> <span class="o">-</span><span class="n">i</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">aws</span> <span class="o">-</span><span class="n">b</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">bin</span><span class="o">/</span><span class="n">aws</span>
</pre></div>


<h2 id="create-cluster-control-plane">Create cluster control plane</h2>
<p>https://us-west-2.console.aws.amazon.com/eks</p>
<p>We can launch via the EKS console: https://console.aws.amazon.com/ek</p>
<p>Input Cluster Name with <code>classCluster</code>, click next</p>
<p>The VPC we need is 192.168.0.0/16 subnet</p>
<p>And Security Group is the right classEKSVPS </p>
<p>After cluster activing, we go to below command line operation</p>
<div class="hlcode"><pre><span class="n">aws</span> <span class="n">configure</span> <span class="o">--</span><span class="n">profile</span><span class="o">=</span><span class="n">clusterAdmin</span> 

<span class="cp"># Key &amp; Secret could get it from IAM console</span>
<span class="n">Default</span> <span class="n">region</span> <span class="n">name</span> <span class="p">[</span><span class="n">Oregon</span><span class="p">]</span><span class="o">:</span> <span class="n">us</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mi">2</span>
<span class="n">Default</span> <span class="n">output</span> <span class="n">format</span> <span class="p">[</span><span class="n">json</span><span class="p">]</span><span class="o">:</span> <span class="n">json</span>
</pre></div>


<p>Enable variables</p>
<div class="hlcode"><pre><span class="n">export</span> <span class="n">AWS_PROFILE</span><span class="o">=</span><span class="n">clusterAdmin</span> <span class="err">#</span> <span class="n">Re</span><span class="o">-</span><span class="n">enable</span> <span class="n">it</span> <span class="n">when</span> <span class="n">you</span> <span class="n">reset</span> <span class="n">your</span> <span class="n">terminal</span> 
</pre></div>


<div class="hlcode"><pre><span class="n">aws</span> <span class="n">eks</span> <span class="n">update</span><span class="o">-</span><span class="n">kubeconfig</span> <span class="o">--</span><span class="n">name</span> <span class="n">classCluster</span>

<span class="cp"># Verify Kubernetes access</span>
<span class="n">And</span> <span class="n">lastly</span><span class="p">,</span> <span class="n">we</span> <span class="n">should</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">confirm</span> <span class="n">our</span> <span class="n">access</span>

<span class="n">kubectl</span> <span class="n">get</span> <span class="n">pods</span>
<span class="n">kubectl</span> <span class="n">get</span> <span class="n">nodes</span>
</pre></div>


<h2 id="create-worker-nodes">Create worker nodes</h2>
<p>Go to EC2 to setup Key Pair with Name <code>clusterAdmin_EC2_keyPair</code></p>
<p>https://console.aws.amazon.com/cloudformation/</p>
<p>create stack with below S3 template<br />
https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-nodegroup.yaml</p>
<p>and then specify the stack name <code>eksNodeStake</code> , Clustername <code>classCluster</code> and VPC with <code>classEKSVPS-ControlPlainSecurity</code></p>
<p>NodeGroupName with <code>workerNodes</code></p>
<p>NodeImageID with below Oregon AMI <code>ami-0a54c984b9f908c81</code></p>
<div class="hlcode"><pre><span class="n">Region</span>                       <span class="n">Amazon</span> <span class="n">EKS</span><span class="o">-</span><span class="n">optimized</span>   <span class="n">AMI</span> <span class="n">with</span> <span class="n">GPU</span> <span class="n">support</span>
<span class="n">US</span> <span class="n">West</span> <span class="p">(</span><span class="n">Oregon</span><span class="p">)</span> <span class="p">(</span><span class="n">us</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>  <span class="n">ami</span><span class="o">-</span><span class="mi">0</span><span class="n">a54c984b9f908c81</span> <span class="n">ami</span><span class="o">-</span><span class="mo">07316</span><span class="mi">94</span><span class="n">d53ef9604b</span>
<span class="n">US</span> <span class="n">East</span> <span class="p">(</span><span class="n">N</span><span class="p">.</span> <span class="n">Va</span><span class="p">)</span>  <span class="p">(</span><span class="n">us</span><span class="o">-</span><span class="n">east</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>    <span class="n">ami</span><span class="o">-</span><span class="mf">0440e4</span><span class="n">f6b9713faf6</span>   <span class="n">ami</span><span class="o">-</span><span class="mo">05</span><span class="mi">8</span><span class="n">bfb8c236caae89</span>
<span class="n">EU</span> <span class="p">(</span><span class="n">Ireland</span><span class="p">)</span>     <span class="p">(</span><span class="n">eu</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>    <span class="n">ami</span><span class="o">-</span><span class="mi">0</span><span class="n">c7a4976cb6fafd3a</span>   <span class="n">ami</span><span class="o">-</span><span class="mo">0706</span><span class="n">dc8a5eed2eed9</span>
</pre></div>


<p>And also complete the rest of option: KeyName, VpsId, Subnets (we have 3), and click next again to go to final page.</p>
<p>acknowledge this create and finish them.</p>
<p>Capture the worker ARN (NodeInstanceRole) from the CloudFormation output.<br />
(store it in our outputs file)</p>
<p>We'll also be updating the aws-auth-cm.yaml document with that ARN</p>
<div class="hlcode"><pre><span class="n">apiVersion</span><span class="o">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">ConfigMap</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">aws</span><span class="o">-</span><span class="n">auth</span>
  <span class="kd">namespace</span><span class="o">:</span> <span class="n">kube</span><span class="o">-</span><span class="n">system</span>
<span class="n">data</span><span class="o">:</span>
  <span class="n">mapRoles</span><span class="o">:</span> <span class="o">|</span>
    <span class="o">-</span> <span class="n">rolearn</span><span class="o">:</span> <span class="n">arn</span><span class="o">:</span><span class="n">xxxxxxxxxxxxxx</span>
      <span class="n">username</span><span class="o">:</span> <span class="n">system</span><span class="o">:</span><span class="n">node</span><span class="o">:{{</span><span class="n">EC2PrivateDNSName</span><span class="o">}}</span>
      <span class="n">groups</span><span class="o">:</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">bootstrappers</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">nodes</span>
</pre></div>


<p>so that the newly created workers have authorization to connect to our EKS control plane, and then installing the configmap to enable the authentication:</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="nx">kubectl</span> <span class="nx">apply</span> <span class="na">-f</span> <span class="nx">aws</span><span class="na">-auth-cm.yaml</span>
<span class="nx">configmap</span> <span class="s2">&quot;aws-auth&quot;</span> <span class="nx">created</span>

<span class="err">$</span> <span class="nx">kubectl</span> <span class="nb">get</span> <span class="nx">nodes</span>
<span class="nb">NAME</span>                                            <span class="nb">STATUS</span>    <span class="nx">ROLES</span>     <span class="nx">AGE</span>       <span class="nb">VERSION</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">126</span><span class="o">-</span><span class="mi">221</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">38</span><span class="nb">s</span>       <span class="nx">v1.10.3</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">133</span><span class="o">-</span><span class="mi">98</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>    <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">37</span><span class="nb">s</span>       <span class="nx">v1.10.3</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">222</span><span class="o">-</span><span class="mi">158</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">40</span><span class="nb">s</span>       <span class="nx">v1.10.3</span>
</pre></div>


<h2 id="scale-policy">Scale policy</h2>
<p>In order to make use of the ASG that the default node cloudformation template creates, we need to add a policy to the group via the EC2 console.</p>
<p>Select Autoscaling Groups, and the third tap Scaling Policies</p>
<p>Create a Policy</p>
<ul>
<li>simple policy defines a target CPU utilization.  I find 70% works well<br />
    for many environments.</li>
<li>Name: <code>scale-70</code> Taget value: 70</li>
</ul>
<p>In our unused cluster, the number of instances should start to shrink.</p>
<div class="hlcode"><pre><span class="err">#</span> <span class="nx">before</span>
<span class="err">$</span> <span class="nx">kubectl</span> <span class="nb">get</span> <span class="nx">nodes</span>
<span class="nb">NAME</span>                                            <span class="nb">STATUS</span>    <span class="nx">ROLES</span>     <span class="nx">AGE</span>       <span class="nb">VERSION</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">126</span><span class="o">-</span><span class="mi">221</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">10</span><span class="nx">m</span>       <span class="nx">v1.10.3</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">133</span><span class="o">-</span><span class="mi">98</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>    <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">10</span><span class="nx">m</span>       <span class="nx">v1.10.3</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">222</span><span class="o">-</span><span class="mi">158</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">10</span><span class="nx">m</span>       <span class="nx">v1.10.3</span>

<span class="err">#</span> <span class="nx">after</span>
<span class="err">$</span> <span class="nx">kubectl</span> <span class="nb">get</span> <span class="nx">nodes</span>
<span class="nb">NAME</span>                                            <span class="nb">STATUS</span>    <span class="nx">ROLES</span>     <span class="nx">AGE</span>       <span class="nb">VERSION</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">222</span><span class="o">-</span><span class="mi">158</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">54</span><span class="nx">m</span>       <span class="nx">v1.10.3</span>
</pre></div>


<h2 id="label-the-nodes">Label the nodes</h2>
<p>Go to CloudFormation and create another template</p>
<p>From S3 template<br />
https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-nodegroup.yaml</p>
<p>specify the name <code>labelNodes</code> , ClusterName <code>classCluster</code>,  NodeGroupName <code>labelNodes</code>,</p>
<p>and pick up the t2.small instances. and NodeImageId with below Oregon ami <code>ami-0a54c984b9f908c81</code></p>
<div class="hlcode"><pre><span class="n">Region</span>                       <span class="n">Amazon</span> <span class="n">EKS</span><span class="o">-</span><span class="n">optimized</span>   <span class="n">AMI</span> <span class="n">with</span> <span class="n">GPU</span> <span class="n">support</span>
<span class="n">US</span> <span class="n">West</span> <span class="p">(</span><span class="n">Oregon</span><span class="p">)</span> <span class="p">(</span><span class="n">us</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>  <span class="n">ami</span><span class="o">-</span><span class="mi">0</span><span class="n">a54c984b9f908c81</span> <span class="n">ami</span><span class="o">-</span><span class="mo">07316</span><span class="mi">94</span><span class="n">d53ef9604b</span>
<span class="n">US</span> <span class="n">East</span> <span class="p">(</span><span class="n">N</span><span class="p">.</span> <span class="n">Va</span><span class="p">)</span>  <span class="p">(</span><span class="n">us</span><span class="o">-</span><span class="n">east</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>    <span class="n">ami</span><span class="o">-</span><span class="mf">0440e4</span><span class="n">f6b9713faf6</span>   <span class="n">ami</span><span class="o">-</span><span class="mo">05</span><span class="mi">8</span><span class="n">bfb8c236caae89</span>
<span class="n">EU</span> <span class="p">(</span><span class="n">Ireland</span><span class="p">)</span>     <span class="p">(</span><span class="n">eu</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>    <span class="n">ami</span><span class="o">-</span><span class="mi">0</span><span class="n">c7a4976cb6fafd3a</span>   <span class="n">ami</span><span class="o">-</span><span class="mo">0706</span><span class="n">dc8a5eed2eed9</span>
</pre></div>


<p>and also BootstrapArguments</p>
<div class="hlcode"><pre><span class="o">--</span><span class="n">kubelet</span><span class="o">-</span><span class="n">extra</span><span class="o">-</span><span class="n">args</span> <span class="err">&#39;</span><span class="o">--</span><span class="n">node</span><span class="o">-</span><span class="n">labels</span> <span class="s">&quot;nodetype=generalpurpose&quot;</span><span class="err">&#39;</span>
</pre></div>


<p>And acknowledge the create resources at final page.</p>
<p>goto labelNodes stack and find arn info and fill up into output.txt</p>
<p>And also append it into aws-auth-cm.yaml</p>
<div class="hlcode"><pre><span class="n">apiVersion</span><span class="o">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">ConfigMap</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">aws</span><span class="o">-</span><span class="n">auth</span>
  <span class="kd">namespace</span><span class="o">:</span> <span class="n">kube</span><span class="o">-</span><span class="n">system</span>
<span class="n">data</span><span class="o">:</span>
  <span class="n">mapRoles</span><span class="o">:</span> <span class="o">|</span>
    <span class="o">-</span> <span class="n">rolearn</span><span class="o">:</span> <span class="n">arn</span><span class="o">:</span><span class="n">aws</span><span class="o">:</span><span class="n">iam</span><span class="o">::</span><span class="mi">959612087337</span><span class="o">:</span><span class="n">role</span><span class="o">/</span><span class="n">eksNodeStack</span><span class="o">-</span><span class="n">NodeInstanceRole</span><span class="o">-</span><span class="n">N6ET9HHZXHSE</span>
      <span class="n">username</span><span class="o">:</span> <span class="n">system</span><span class="o">:</span><span class="n">node</span><span class="o">:{{</span><span class="n">EC2PrivateDNSName</span><span class="o">}}</span>
      <span class="n">groups</span><span class="o">:</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">bootstrappers</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">nodes</span>
    <span class="o">-</span> <span class="n">rolearn</span><span class="o">:</span> <span class="n">arn</span><span class="o">:</span><span class="n">aws</span><span class="o">:</span><span class="n">iam</span><span class="o">::</span><span class="mi">959612087337</span><span class="o">:</span><span class="n">role</span><span class="o">/</span><span class="n">labelNodes</span><span class="o">-</span><span class="n">NodeInstanceRole</span><span class="o">-</span><span class="n">HDIXQW4LUDF7</span>
      <span class="n">username</span><span class="o">:</span> <span class="n">system</span><span class="o">:</span><span class="n">node</span><span class="o">:{{</span><span class="n">EC2PrivateDNSName</span><span class="o">}}</span>
      <span class="n">groups</span><span class="o">:</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">bootstrappers</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">nodes</span>
</pre></div>


<p>Apply the yaml file</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="nx">kubectl</span> <span class="nx">apply</span> <span class="na">-f</span> <span class="nx">aws</span><span class="na">-auth-cm.yaml</span>
<span class="nx">configmap</span> <span class="s2">&quot;aws-auth&quot;</span> <span class="nx">configured</span>

<span class="err">$</span> <span class="nx">kubectl</span> <span class="nb">get</span> <span class="nx">nodes</span>
<span class="nb">NAME</span>                                            <span class="nb">STATUS</span>    <span class="nx">ROLES</span>     <span class="nx">AGE</span>       <span class="nb">VERSION</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">111</span><span class="o">-</span><span class="mi">130</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">42</span><span class="nb">s</span>       <span class="nx">v1.10.3</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">133</span><span class="o">-</span><span class="mi">251</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">40</span><span class="nb">s</span>       <span class="nx">v1.10.3</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">222</span><span class="o">-</span><span class="mi">158</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">2</span><span class="nx">h</span>        <span class="nx">v1.10.3</span>
<span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">236</span><span class="o">-</span><span class="mi">150</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span>   <span class="nb">Ready</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>    <span class="mi">38</span><span class="nb">s</span>       <span class="nx">v1.10.3</span>
</pre></div>


<p>and also hostname.yaml</p>
<div class="hlcode"><pre><span class="n">apiVersion</span><span class="o">:</span> <span class="n">extensions</span><span class="o">/</span><span class="n">v1beta1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">Deployment</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v2</span>
<span class="n">spec</span><span class="o">:</span>
  <span class="n">replicas</span><span class="o">:</span> <span class="mi">1</span>
  <span class="n">template</span><span class="o">:</span>
    <span class="n">metadata</span><span class="o">:</span>
      <span class="n">labels</span><span class="o">:</span>
        <span class="n">app</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v2</span>
        <span class="n">version</span><span class="o">:</span> <span class="n">v2</span>
    <span class="n">spec</span><span class="o">:</span>
      <span class="n">containers</span><span class="o">:</span>
      <span class="o">-</span> <span class="n">image</span><span class="o">:</span> <span class="n">rstarmer</span><span class="o">/</span><span class="n">hostname</span><span class="o">:</span><span class="n">v2</span>
        <span class="n">imagePullPolicy</span><span class="o">:</span> <span class="n">Always</span>
        <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span>
      <span class="n">nodeSelector</span><span class="o">:</span>
        <span class="n">nodetype</span><span class="o">:</span> <span class="n">generalpurpose</span>
<span class="o">---</span>
<span class="n">apiVersion</span><span class="o">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">Service</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">labels</span><span class="o">:</span>
    <span class="n">app</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v2</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v2</span>
<span class="n">spec</span><span class="o">:</span>
  <span class="n">ports</span><span class="o">:</span>
  <span class="o">-</span> <span class="n">name</span><span class="o">:</span> <span class="n">web</span>
    <span class="n">port</span><span class="o">:</span> <span class="mi">80</span>
    <span class="n">protocol</span><span class="o">:</span> <span class="n">TCP</span>
    <span class="n">targetPort</span><span class="o">:</span> <span class="mi">80</span>
  <span class="n">selector</span><span class="o">:</span>
    <span class="n">app</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v2</span>
</pre></div>


<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">apply</span> <span class="o">-</span><span class="n">f</span> <span class="n">hostname</span><span class="p">.</span><span class="n">yaml</span>
<span class="n">deployment</span><span class="p">.</span><span class="n">extensions</span> <span class="s">&quot;hostname-v2&quot;</span> <span class="n">created</span>
<span class="n">service</span> <span class="s">&quot;hostname-v2&quot;</span> <span class="n">created</span>
</pre></div>


<div class="hlcode"><pre><span class="err">$</span> <span class="nx">kubectl</span> <span class="nb">describe</span> <span class="nx">pod</span> <span class="nb">hostname</span><span class="na">-v2</span><span class="o">-</span><span class="mi">6499</span><span class="nx">cb8cc8</span><span class="o">-</span><span class="mi">2</span><span class="nx">wzmm</span>
<span class="nb">Name</span><span class="p">:</span>               <span class="nb">hostname</span><span class="na">-v2</span><span class="o">-</span><span class="mi">6499</span><span class="nx">cb8cc8</span><span class="o">-</span><span class="mi">2</span><span class="nx">wzmm</span>
<span class="nx">Namespace</span><span class="p">:</span>          <span class="nb">default</span>
<span class="nx">Priority</span><span class="p">:</span>           <span class="mi">0</span>
<span class="nx">PriorityClassName</span><span class="p">:</span>  <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>
<span class="nx">Node</span><span class="p">:</span>               <span class="nx">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">236</span><span class="o">-</span><span class="mi">150</span><span class="bp">.</span><span class="nx">us</span><span class="na">-west</span><span class="o">-</span><span class="mi">2</span><span class="bp">.</span><span class="nx">compute.internal</span><span class="p">/</span><span class="nx">192.168.236.150</span>
<span class="nb">Start</span> <span class="nb">Time</span><span class="p">:</span>         <span class="nx">Wed</span><span class="p">,</span> <span class="mi">06</span> <span class="nx">Mar</span> <span class="mi">2019</span> <span class="mi">17</span><span class="p">:</span><span class="mi">01</span><span class="p">:</span><span class="mi">10</span> <span class="o">+</span><span class="mi">0800</span>
<span class="nx">Labels</span><span class="p">:</span>             <span class="n">app</span><span class="o">=</span><span class="nb">hostname</span><span class="na">-v2</span>
                    <span class="nx">pod</span><span class="na">-template-hash</span><span class="o">=</span><span class="mi">2055764774</span>
                    <span class="n">version</span><span class="o">=</span><span class="nx">v2</span>
<span class="nx">...</span>
<span class="nx">...</span>
</pre></div>


<h2 id="create-an-elb">create an ELB</h2>
<p>aws iam create-service-linked-role --aws-service-name elasticloadbalancing.amazonaws.com</p>
<p>By default EKS doesn't have any storage classes defined, and we need to have a storage class model in order to be able to create persistent storage.</p>
<p>Luckily the 'plumbing' is already there, and we simply have to enable our storage class connection to the underlying EBS service.</p>
<p>gp-storage.yaml</p>
<div class="hlcode"><pre><span class="n">kind</span><span class="o">:</span> <span class="n">StorageClass</span>
<span class="n">apiVersion</span><span class="o">:</span> <span class="n">storage</span><span class="o">.</span><span class="na">k8s</span><span class="o">.</span><span class="na">io</span><span class="o">/</span><span class="n">v1</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">gp2</span>
  <span class="n">annotations</span><span class="o">:</span>
    <span class="n">storageclass</span><span class="o">.</span><span class="na">kubernetes</span><span class="o">.</span><span class="na">io</span><span class="o">/</span><span class="k">is</span><span class="o">-</span><span class="k">default</span><span class="o">-</span><span class="kd">class</span><span class="o">:</span> <span class="s1">&#39;true&#39;</span>
<span class="n">provisioner</span><span class="o">:</span> <span class="n">kubernetes</span><span class="o">.</span><span class="na">io</span><span class="o">/</span><span class="n">aws</span><span class="o">-</span><span class="n">ebs</span>
<span class="n">parameters</span><span class="o">:</span>
  <span class="n">type</span><span class="o">:</span> <span class="n">gp2</span>
<span class="n">reclaimPolicy</span><span class="o">:</span> <span class="n">Retain</span>
<span class="n">mountOptions</span><span class="o">:</span>
  <span class="o">-</span> <span class="n">debug</span>
</pre></div>


<p>This creates a "standard" EBS based volume when a persistent volume request is created.  Size is determined by the persistent volume request.</p>
<p>In addition, we have configured this resource as our default, so if an application asks for storage without defining a class, we'll get this class configured.</p>
<p>Creating some Fast (100iops/GB) SSD Storage is also straightforward:</p>
<p>fast-storage.yaml</p>
<div class="hlcode"><pre><span class="n">kind</span><span class="o">:</span> <span class="n">StorageClass</span>
<span class="n">apiVersion</span><span class="o">:</span> <span class="n">storage</span><span class="o">.</span><span class="na">k8s</span><span class="o">.</span><span class="na">io</span><span class="o">/</span><span class="n">v1</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">fast</span><span class="o">-</span><span class="mi">100</span>
<span class="n">provisioner</span><span class="o">:</span> <span class="n">kubernetes</span><span class="o">.</span><span class="na">io</span><span class="o">/</span><span class="n">aws</span><span class="o">-</span><span class="n">ebs</span>
<span class="n">parameters</span><span class="o">:</span>
  <span class="n">type</span><span class="o">:</span> <span class="n">io1</span>
  <span class="n">iopsPerGB</span><span class="o">:</span> <span class="s2">&quot;100&quot;</span>
<span class="n">reclaimPolicy</span><span class="o">:</span> <span class="n">Retain</span>
<span class="n">mountOptions</span><span class="o">:</span>
  <span class="o">-</span> <span class="n">debug</span>
</pre></div>


<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">create</span> <span class="o">-</span><span class="n">f</span> <span class="n">gp</span><span class="o">-</span><span class="n">storage</span><span class="p">.</span><span class="n">yaml</span> <span class="o">-</span><span class="n">f</span> <span class="n">fast</span><span class="o">-</span><span class="n">storage</span><span class="p">.</span><span class="n">html</span>
<span class="n">storageclass</span><span class="p">.</span><span class="n">storage</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;gp2&quot;</span> <span class="n">created</span>
<span class="n">storageclass</span><span class="p">.</span><span class="n">storage</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;fast-100&quot;</span> <span class="n">created</span>

<span class="err">$</span> <span class="n">kubectl</span> <span class="n">get</span> <span class="n">storageclasses</span>
<span class="n">NAME</span>            <span class="n">PROVISIONER</span>             <span class="n">AGE</span>
<span class="n">fast</span><span class="o">-</span><span class="mi">100</span>        <span class="n">kubernetes</span><span class="p">.</span><span class="n">io</span><span class="o">/</span><span class="n">aws</span><span class="o">-</span><span class="n">ebs</span>   <span class="mi">15</span><span class="n">s</span>
<span class="n">gp2</span> <span class="p">(</span><span class="k">default</span><span class="p">)</span>   <span class="n">kubernetes</span><span class="p">.</span><span class="n">io</span><span class="o">/</span><span class="n">aws</span><span class="o">-</span><span class="n">ebs</span>   <span class="mi">15</span><span class="n">s</span>
</pre></div>


<p>Additional parameters are available to tune for different classes of storage, and they are defined here:<br />
https://kubernetes.io/docs/concepts/storage/storage-classes/#aws-ebs</p>
<h3 id="mapping-storage">Mapping storage</h3>
<p>Once storage classes are defined, mapping uses the standard Kubernetes models, and as we defined "Retain" as the reclaim policy, we have storage<br />
that maintains persistence even when we delete the PersistentVolumeClaim and the Pod that claimed the storage.</p>
<p>Let's create a simple app that gets a 10G volume and mounts it into the web directory:</p>
<p>hostname-volume.yaml</p>
<div class="hlcode"><pre><span class="n">apiVersion</span><span class="o">:</span> <span class="n">extensions</span><span class="o">/</span><span class="n">v1beta1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">Deployment</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">volume</span>
<span class="n">spec</span><span class="o">:</span>
  <span class="n">replicas</span><span class="o">:</span> <span class="mi">1</span>
  <span class="n">template</span><span class="o">:</span>
    <span class="n">metadata</span><span class="o">:</span>
      <span class="n">labels</span><span class="o">:</span>
        <span class="n">app</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">volume</span>
        <span class="n">version</span><span class="o">:</span> <span class="n">v1</span>
    <span class="n">spec</span><span class="o">:</span>
      <span class="n">volumes</span><span class="o">:</span>
      <span class="o">-</span> <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">pvc</span>
        <span class="n">persistentVolumeClaim</span><span class="o">:</span>
          <span class="n">claimName</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">pvc</span>
      <span class="n">containers</span><span class="o">:</span>
      <span class="o">-</span> <span class="n">image</span><span class="o">:</span> <span class="n">rstarmer</span><span class="o">/</span><span class="n">hostname</span><span class="o">:</span><span class="n">v1</span>
        <span class="n">imagePullPolicy</span><span class="o">:</span> <span class="n">Always</span>
        <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span>
        <span class="n">volumeMounts</span><span class="o">:</span>
          <span class="o">-</span> <span class="n">mountPath</span><span class="o">:</span> <span class="s2">&quot;/www&quot;</span>
            <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">pvc</span>
<span class="o">---</span>
<span class="n">apiVersion</span><span class="o">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">Service</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">labels</span><span class="o">:</span>
    <span class="n">app</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">volume</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">volume</span>
<span class="n">spec</span><span class="o">:</span>
  <span class="n">ports</span><span class="o">:</span>
  <span class="o">-</span> <span class="n">name</span><span class="o">:</span> <span class="n">web</span>
    <span class="n">port</span><span class="o">:</span> <span class="mi">80</span>
    <span class="n">protocol</span><span class="o">:</span> <span class="n">TCP</span>
    <span class="n">targetPort</span><span class="o">:</span> <span class="mi">80</span>
  <span class="n">selector</span><span class="o">:</span>
    <span class="n">app</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">volume</span>
<span class="o">---</span>
<span class="n">apiVersion</span><span class="o">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">PersistentVolumeClaim</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">pvc</span>
<span class="n">spec</span><span class="o">:</span>
  <span class="n">storageClassName</span><span class="o">:</span> <span class="n">gp2</span>
  <span class="n">accessModes</span><span class="o">:</span>
    <span class="o">-</span> <span class="n">ReadWriteOnce</span>
  <span class="n">resources</span><span class="o">:</span>
    <span class="n">requests</span><span class="o">:</span>
      <span class="n">storage</span><span class="o">:</span> <span class="mi">1</span><span class="n">Gi</span>
</pre></div>


<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">create</span> <span class="o">-</span><span class="n">f</span> <span class="n">hostname</span><span class="o">-</span><span class="n">volume</span><span class="p">.</span><span class="n">yaml</span>
<span class="n">deployment</span><span class="p">.</span><span class="n">extensions</span> <span class="s">&quot;hostname-volume&quot;</span> <span class="n">created</span>
<span class="n">service</span> <span class="s">&quot;hostname-volume&quot;</span> <span class="n">created</span>
<span class="n">persistentvolumeclaim</span> <span class="s">&quot;hostname-pvc&quot;</span> <span class="n">created</span>

<span class="err">$</span> <span class="n">kubectl</span> <span class="n">get</span> <span class="n">pv</span>
<span class="n">NAME</span>                                       <span class="n">CAPACITY</span>   <span class="n">ACCESS</span> <span class="n">MODES</span>   <span class="n">RECLAIM</span> <span class="n">POLICY</span>   <span class="n">STATUS</span>    <span class="n">CLAIM</span>                  <span class="n">STORAGECLASS</span>   <span class="n">REASON</span>    <span class="n">AGE</span>
<span class="n">pvc</span><span class="o">-</span><span class="n">ac9533df</span><span class="o">-</span><span class="mf">3ff</span><span class="n">b</span><span class="o">-</span><span class="mf">11e9</span><span class="o">-</span><span class="n">b634</span><span class="o">-</span><span class="mi">0</span><span class="n">acae188e214</span>   <span class="mi">1</span><span class="n">Gi</span>        <span class="n">RWO</span>            <span class="n">Retain</span>           <span class="n">Bound</span>     <span class="k">default</span><span class="o">/</span><span class="n">hostname</span><span class="o">-</span><span class="n">pvc</span>   <span class="n">gp2</span>                      <span class="mi">15</span><span class="n">s</span>

<span class="err">$</span> <span class="n">kubectl</span> <span class="n">get</span> <span class="n">pvc</span> <span class="o">-</span><span class="n">o</span> <span class="n">wide</span>
<span class="n">NAME</span>           <span class="n">STATUS</span>    <span class="n">VOLUME</span>                                     <span class="n">CAPACITY</span>   <span class="n">ACCESS</span> <span class="n">MODES</span>   <span class="n">STORAGECLASS</span>   <span class="n">AGE</span>
<span class="n">hostname</span><span class="o">-</span><span class="n">pvc</span>   <span class="n">Bound</span>     <span class="n">pvc</span><span class="o">-</span><span class="n">ac9533df</span><span class="o">-</span><span class="mf">3ff</span><span class="n">b</span><span class="o">-</span><span class="mf">11e9</span><span class="o">-</span><span class="n">b634</span><span class="o">-</span><span class="mi">0</span><span class="n">acae188e214</span>   <span class="mi">1</span><span class="n">Gi</span>        <span class="n">RWO</span>            <span class="n">gp2</span>            <span class="mi">27</span><span class="n">s</span>

<span class="err">$</span> <span class="n">kubectl</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span> <span class="o">-</span><span class="n">l</span> <span class="n">app</span><span class="o">=</span><span class="n">hostname</span><span class="o">-</span><span class="n">volume</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">items</span><span class="p">..</span><span class="n">metadata</span><span class="p">.</span><span class="n">name</span><span class="p">})</span> <span class="o">--</span> <span class="n">df</span> <span class="o">-</span><span class="n">h</span> <span class="o">/</span><span class="n">www</span>
<span class="n">Filesystem</span>      <span class="n">Size</span>  <span class="n">Used</span> <span class="n">Avail</span> <span class="n">Use</span><span class="o">%</span> <span class="n">Mounted</span> <span class="n">on</span>
<span class="o">/</span><span class="n">dev</span><span class="o">/</span><span class="n">xvdck</span>      <span class="mi">976</span><span class="n">M</span>  <span class="mf">2.6</span><span class="n">M</span>  <span class="mi">907</span><span class="n">M</span>   <span class="mi">1</span><span class="o">%</span> <span class="o">/</span><span class="n">www</span>

<span class="err">$</span> <span class="n">kubectl</span> <span class="n">get</span> <span class="n">pods</span>
<span class="n">NAME</span>                               <span class="n">READY</span>     <span class="n">STATUS</span>    <span class="n">RESTARTS</span>   <span class="n">AGE</span>
<span class="n">hostname</span><span class="o">-</span><span class="n">v2</span><span class="o">-</span><span class="mi">6499</span><span class="n">cb8cc8</span><span class="o">-</span><span class="mi">2</span><span class="n">wzmm</span>       <span class="mi">1</span><span class="o">/</span><span class="mi">1</span>       <span class="n">Running</span>   <span class="mi">0</span>          <span class="mi">1</span><span class="n">h</span>
<span class="n">hostname</span><span class="o">-</span><span class="n">volume</span><span class="o">-</span><span class="mf">8479ff</span><span class="n">dd6f</span><span class="o">-</span><span class="n">lsj84</span>   <span class="mi">1</span><span class="o">/</span><span class="mi">1</span>       <span class="n">Running</span>   <span class="mi">0</span>          <span class="mi">1</span><span class="n">m</span>
</pre></div>


<p>We can see that there is now a PV that is created with a PVC that claims it, and if we check our pod, we can see that our www directory is empty (because it has a 1G volume mounted to it).</p>
<h3 id="clean-up-the-storage">Clean up the storage</h3>
<p>A simple challenge.  We can clean up our hostname-volume "stack" with:</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">delete</span> <span class="o">-</span><span class="n">f</span> <span class="n">hostname</span><span class="o">-</span><span class="n">volume</span><span class="p">.</span><span class="n">yaml</span>
</pre></div>


<p>But this leaves a resource behind. If we really want to clean up <em>all</em> of our storage, how would we go about cleaning up the volumes themselves.</p>
<p>The solution is simple:</p>
<p>First remove the "stack" we created earlier:</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">delete</span> <span class="o">-</span><span class="n">f</span> <span class="n">hostname</span><span class="o">-</span><span class="n">volume</span><span class="p">.</span><span class="n">yaml</span>
<span class="n">deployment</span><span class="p">.</span><span class="n">extensions</span> <span class="s">&quot;hostname-volume&quot;</span> <span class="n">deleted</span>
<span class="n">service</span> <span class="s">&quot;hostname-volume&quot;</span> <span class="n">deleted</span>
<span class="n">persistentvolumeclaim</span> <span class="s">&quot;hostname-pvc&quot;</span> <span class="n">deleted</span>
</pre></div>


<p>Then clean up the PV itself.  Note, you do <em>not</em> want to do this if there are more than one PVs created, as this will grab <em>all</em> of the volumes and delete them!</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">get</span> <span class="n">pv</span>
<span class="n">NAME</span>                                       <span class="n">CAPACITY</span>   <span class="n">ACCESS</span> <span class="n">MODES</span>   <span class="n">RECLAIM</span> <span class="n">POLICY</span>   <span class="n">STATUS</span>    <span class="n">CLAIM</span>                  <span class="n">STORAGECLASS</span>   <span class="n">REASON</span>    <span class="n">AGE</span>
<span class="n">pvc</span><span class="o">-</span><span class="n">ac9533df</span><span class="o">-</span><span class="mf">3ff</span><span class="n">b</span><span class="o">-</span><span class="mf">11e9</span><span class="o">-</span><span class="n">b634</span><span class="o">-</span><span class="mi">0</span><span class="n">acae188e214</span>   <span class="mi">1</span><span class="n">Gi</span>        <span class="n">RWO</span>            <span class="n">Retain</span>           <span class="n">Bound</span>     <span class="k">default</span><span class="o">/</span><span class="n">hostname</span><span class="o">-</span><span class="n">pvc</span>   <span class="n">gp2</span>                      <span class="mi">6</span><span class="n">m</span>

<span class="err">$</span> <span class="n">kubectl</span> <span class="n">delete</span> <span class="n">pv</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pv</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">items</span><span class="p">..</span><span class="n">metadata</span><span class="p">.</span><span class="n">name</span><span class="p">})</span>
<span class="n">persistentvolume</span> <span class="s">&quot;pvc-ac9533df-3ffb-11e9-b634-0acae188e214&quot;</span> <span class="n">deleted</span>
</pre></div>


<h2 id="networking">Networking</h2>
<p>Networking in EKS uses the VPC-CNI project to use the AWS VPC network model to provide connectivity across the cluster.  This is more efficient than having another layer of networking (e.g. Flannel, Calico, Weave, etc.) deployed as an overlay on top of the system, and maps perfectly into the VPC environment, using the VPC network management and IPAM services to support address management further improving the efficiency of the overall Kubernetes deployment.</p>
<p>We can see this in action by looking at the network information for any pod in the system:</p>
<div class="hlcode"><pre><span class="cp"># deprecated, but a simple way to run a pod</span>
<span class="err">$</span> <span class="n">kubectl</span> <span class="n">run</span> <span class="o">--</span><span class="n">image</span> <span class="n">alpine</span> <span class="n">alpine</span> <span class="n">sleep</span> <span class="mi">3600</span>
<span class="n">deployment</span><span class="p">.</span><span class="n">apps</span> <span class="s">&quot;alpine&quot;</span> <span class="n">created</span> 

<span class="err">$</span> <span class="n">IPs</span><span class="o">=</span><span class="err">`</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span> <span class="o">-</span><span class="n">l</span> <span class="n">run</span><span class="o">=</span><span class="n">alpine</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">items</span><span class="p">..</span><span class="n">metadata</span><span class="p">.</span><span class="n">name</span><span class="p">})</span> <span class="o">-</span><span class="n">o</span> <span class="n">yaml</span> <span class="o">|</span> <span class="n">awk</span> <span class="err">&#39;</span><span class="o">/</span><span class="n">IP</span><span class="o">/</span> <span class="p">{</span><span class="n">print</span> <span class="err">$</span><span class="mi">2</span><span class="p">}</span><span class="err">&#39;`</span>


<span class="err">$</span> <span class="n">echo</span> <span class="err">$</span><span class="n">IPs</span>
<span class="mf">192.168.222.158</span> <span class="mf">192.168.196.154</span>

<span class="cp"># get pods IPs</span>
<span class="err">$</span> <span class="k">for</span> <span class="n">n</span> <span class="n">in</span> <span class="err">$</span><span class="n">IPs</span><span class="p">;</span> <span class="k">do</span> <span class="n">kubectl</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span> <span class="o">-</span><span class="n">l</span> <span class="n">run</span><span class="o">=</span><span class="n">alpine</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">items</span><span class="p">..</span><span class="n">metadata</span><span class="p">.</span><span class="n">name</span><span class="p">})</span>  <span class="n">traceroute</span> <span class="err">$</span><span class="n">n</span> <span class="p">;</span> <span class="n">done</span>
<span class="n">traceroute</span> <span class="n">to</span> <span class="mf">192.168.222.158</span> <span class="p">(</span><span class="mf">192.168.222.158</span><span class="p">),</span> <span class="mi">30</span> <span class="n">hops</span> <span class="n">max</span><span class="p">,</span> <span class="mi">46</span> <span class="n">byte</span> <span class="n">packets</span>
 <span class="mi">1</span>  <span class="n">ip</span><span class="o">-</span><span class="mi">192</span><span class="o">-</span><span class="mi">168</span><span class="o">-</span><span class="mi">222</span><span class="o">-</span><span class="mf">158.</span><span class="n">us</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mf">2.</span><span class="n">compute</span><span class="p">.</span><span class="n">internal</span> <span class="p">(</span><span class="mf">192.168.222.158</span><span class="p">)</span>  <span class="mf">0.005</span> <span class="n">ms</span>  <span class="mf">0.004</span> <span class="n">ms</span>  <span class="mf">0.002</span> <span class="n">ms</span>
<span class="n">traceroute</span> <span class="n">to</span> <span class="mf">192.168.196.154</span> <span class="p">(</span><span class="mf">192.168.196.154</span><span class="p">),</span> <span class="mi">30</span> <span class="n">hops</span> <span class="n">max</span><span class="p">,</span> <span class="mi">46</span> <span class="n">byte</span> <span class="n">packets</span>
 <span class="mi">1</span>  <span class="n">alpine</span><span class="o">-</span><span class="mi">6</span><span class="n">b9858595b</span><span class="o">-</span><span class="n">n9xqt</span> <span class="p">(</span><span class="mf">192.168.196.154</span><span class="p">)</span>  <span class="mf">0.005</span> <span class="n">ms</span>  <span class="mf">0.004</span> <span class="n">ms</span>  <span class="mf">0.003</span> <span class="n">ms</span>
</pre></div>


<h3 id="ingress">Ingress</h3>
<p>Adding ingress is a Kubernetes function</p>
<p>We'll add the traffic load balancer as an ingress function, and make use of the EKS integration with Amazon ELB to enable external access.</p>
<p>As ingress can route based on DNS, we can also do a little DNS manipulation to get traffic routed to our resources.</p>
<p>1) Since we're using 1.10.0 Kubernetes (or newer) we'll need to make sure we have a cluster role binding for the services to use:</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">apply</span> <span class="o">-</span><span class="n">f</span> <span class="n">https</span><span class="o">:</span><span class="c1">//raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml</span>
<span class="n">clusterrole</span><span class="p">.</span><span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;traefik-ingress-controller&quot;</span> <span class="n">created</span>
<span class="n">clusterrolebinding</span><span class="p">.</span><span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;traefik-ingress-controller&quot;</span> <span class="n">created</span>
</pre></div>


<p>2) We'll leverage the deployment model for our ingress controller, as we don't necessarily want to bind host address, and would rather have the ingress transit through the normal kube-proxy functions (note that we're changing the default "NodePort" type to "LoadBalancer"):</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="nx">kubectl</span> <span class="nx">apply</span> <span class="na">-f</span> <span class="o">&lt;</span><span class="p">(</span><span class="nb">curl</span> <span class="na">-so</span> <span class="o">-</span> <span class="nx">https</span><span class="p">:</span><span class="c1">//raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml | sed -e &#39;s/NodePort/LoadBalancer/&#39;)</span>
<span class="nx">serviceaccount</span> <span class="s2">&quot;traefik-ingress-controller&quot;</span> <span class="nx">created</span>
<span class="nx">deployment.extensions</span> <span class="s2">&quot;traefik-ingress-controller&quot;</span> <span class="nx">created</span>
<span class="nx">service</span> <span class="s2">&quot;traefik-ingress-service&quot;</span> <span class="nx">created</span>

<span class="err">$</span> <span class="nx">kubectl</span> <span class="nb">get</span> <span class="nx">svc</span>
<span class="nb">NAME</span>          <span class="k">TYPE</span>        <span class="nx">CLUSTER</span><span class="na">-IP</span>     <span class="nx">EXTERNAL</span><span class="na">-IP</span>   <span class="nb">PORT</span><span class="p">(</span><span class="nb">S</span><span class="p">)</span>   <span class="nx">AGE</span>
<span class="nb">hostname</span><span class="na">-v2</span>   <span class="nx">ClusterIP</span>   <span class="mf">10.100.137.6</span>   <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>        <span class="mi">80</span><span class="p">/</span><span class="nx">TCP</span>    <span class="mi">1</span><span class="nx">h</span>
<span class="nx">kubernetes</span>    <span class="nx">ClusterIP</span>   <span class="mf">10.100.0.1</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>        <span class="mi">443</span><span class="p">/</span><span class="nx">TCP</span>   <span class="mi">6</span><span class="nx">h</span>

<span class="err">$</span> <span class="nx">kubectl</span> <span class="nb">get</span> <span class="nx">svc</span> <span class="na">-n</span> <span class="nx">kube</span><span class="na">-system</span>
<span class="nb">NAME</span>                      <span class="k">TYPE</span>           <span class="nx">CLUSTER</span><span class="na">-IP</span>      <span class="nx">EXTERNAL</span><span class="na">-IP</span>        <span class="nb">PORT</span><span class="p">(</span><span class="nb">S</span><span class="p">)</span>                       <span class="nx">AGE</span>
<span class="nx">kube</span><span class="na">-dns</span>                  <span class="nx">ClusterIP</span>      <span class="mf">10.100.0.10</span>     <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>             <span class="mi">53</span><span class="p">/</span><span class="nx">UDP</span><span class="p">,</span><span class="mi">53</span><span class="p">/</span><span class="nx">TCP</span>                 <span class="mi">6</span><span class="nx">h</span>
<span class="nx">traefik</span><span class="na">-ingress-service</span>   <span class="nx">LoadBalancer</span>   <span class="mf">10.100.220.28</span>   <span class="nx">aeeec6e723ffd...</span>   <span class="mi">80</span><span class="p">:</span><span class="mi">30763</span><span class="p">/</span><span class="nx">TCP</span><span class="p">,</span><span class="mi">8080</span><span class="p">:</span><span class="mi">30982</span><span class="p">/</span><span class="nx">TCP</span>   <span class="mi">55</span><span class="nb">s</span>
</pre></div>


<p>3) We can now expose our hostname app as an ingress resource:</p>
<p>hostname-ingress.yaml</p>
<div class="hlcode"><pre><span class="o">---</span>
<span class="nl">apiVersion:</span> <span class="n">extensions</span><span class="o">/</span><span class="n">v1beta1</span>
<span class="nl">kind:</span> <span class="n">Ingress</span>
<span class="nl">metadata:</span>
  <span class="nl">name:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">ingress</span>
  <span class="nl">namespace:</span> <span class="k">default</span>
<span class="nl">spec:</span>
  <span class="nl">rules:</span>
  <span class="o">-</span> <span class="n">host</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v1</span><span class="p">.</span><span class="n">local</span>
    <span class="nl">http:</span>
      <span class="nl">paths:</span>
      <span class="o">-</span> <span class="n">path</span><span class="o">:</span> <span class="o">/</span>
        <span class="nl">backend:</span>
          <span class="nl">serviceName:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v1</span>
          <span class="nl">servicePort:</span> <span class="n">web</span>
</pre></div>


<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">create</span> <span class="o">-</span><span class="n">f</span> <span class="n">hostname</span><span class="o">-</span><span class="n">ingress</span><span class="p">.</span><span class="n">yaml</span>
<span class="n">ingress</span><span class="p">.</span><span class="n">extensions</span> <span class="s">&quot;hostname-ingress&quot;</span> <span class="n">created</span>
</pre></div>


<p>Note that it assumes a hostname of traefik-ui.minikube, so we can confirm access as follows:</p>
<p>1) Get the loadbalancer service address:</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">export</span> <span class="n">INGRESS</span><span class="o">=</span><span class="err">`</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">svc</span> <span class="o">-</span><span class="n">n</span> <span class="n">kube</span><span class="o">-</span><span class="n">system</span> <span class="n">traefik</span><span class="o">-</span><span class="n">ingress</span><span class="o">-</span><span class="n">service</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">status</span><span class="p">.</span><span class="n">loadBalancer</span><span class="p">.</span><span class="n">ingress</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">hostname</span><span class="p">}</span><span class="err">`</span>

<span class="err">$</span> <span class="n">echo</span> <span class="err">$</span><span class="n">INGRESS</span>
<span class="n">aeeec6e723ffd11e9b6340acae188e21</span><span class="o">-</span><span class="mf">56059226.</span><span class="n">us</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="mf">2.</span><span class="n">elb</span><span class="p">.</span><span class="n">amazonaws</span><span class="p">.</span><span class="n">com</span>
</pre></div>


<p>Capture the actual IP of one of the loadbalancers in the set:</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">export</span> <span class="n">INGRESS_ADDR</span><span class="o">=</span><span class="err">`</span><span class="n">host</span> <span class="err">$</span><span class="n">INGRESS</span> <span class="o">|</span> <span class="n">head</span> <span class="o">-</span><span class="mi">1</span> <span class="o">|</span> <span class="n">cut</span> <span class="o">-</span><span class="n">d</span><span class="sc">&#39; &#39;</span> <span class="o">-</span><span class="n">f</span> <span class="mi">4</span><span class="err">`</span>

<span class="err">$</span> <span class="n">echo</span> <span class="err">$</span><span class="n">INGRESS_ADDR</span>
<span class="mf">34.213.98.29</span>
</pre></div>


<p>Verify that it's responding to web requests:</p>
<div class="hlcode"><pre>curl -sLo /dev/null -Hhost:hostname-v1.local http://<span class="cp">${</span><span class="n">INGRESS_ADDR</span><span class="cp">}</span>/ -w &quot;%{http_code}\n&quot;
</pre></div>


<p>Add an entry to the local /etc/hosts file to point to our resource:</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">echo</span> <span class="s">&quot;$INGRESS_ADDR hostname-v1.local&quot;</span> <span class="o">|</span> <span class="n">sudo</span> <span class="n">tee</span> <span class="o">-</span><span class="n">a</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">hosts</span>
<span class="mf">34.213.98.29</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v1</span><span class="p">.</span><span class="n">local</span>
</pre></div>


<p>Now try pointing a web browser at that hostname:</p>
<p>http://hostname-v1.local</p>
<h3 id="network-policy-with-callco">Network Policy with Callco</h3>
<p>Enable_Calico_Policy.md<br />
In order to enable policy, a CNI network needs to be in place, and by default the VPC based networking in EKS is already configured appropriately.  Policy however is not part of the VPC networking provided by Amazon, and instead, an integration with the Calico policy manager has been integrated with the VPC CNI service.</p>
<p>Enabling this function is as simple as launching the calico CNI policy manifest from the Amazon VPC CNI project:</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">apply</span> <span class="o">-</span><span class="n">f</span> <span class="n">https</span><span class="o">:</span><span class="c1">//raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/release-1.1/config/v1.1/calico.yaml --validate=false</span>
<span class="n">daemonset</span><span class="p">.</span><span class="n">extensions</span> <span class="s">&quot;calico-node&quot;</span> <span class="n">configured</span>
<span class="n">customresourcedefinition</span><span class="p">.</span><span class="n">apiextensions</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;felixconfigurations.crd.projectcalico.org&quot;</span> <span class="n">created</span>
<span class="n">customresourcedefinition</span><span class="p">.</span><span class="n">apiextensions</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;bgpconfigurations.crd.projectcalico.org&quot;</span> <span class="n">created</span>
<span class="n">customresourcedefinition</span><span class="p">.</span><span class="n">apiextensions</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;ippools.crd.projectcalico.org&quot;</span> <span class="n">created</span>
<span class="n">customresourcedefinition</span><span class="p">.</span><span class="n">apiextensions</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;hostendpoints.crd.projectcalico.org&quot;</span> <span class="n">created</span>
<span class="n">customresourcedefinition</span><span class="p">.</span><span class="n">apiextensions</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;clusterinformations.crd.projectcalico.org&quot;</span> <span class="n">created</span>
<span class="n">customresourcedefinition</span><span class="p">.</span><span class="n">apiextensions</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;globalnetworkpolicies.crd.projectcalico.org&quot;</span> <span class="n">created</span>
<span class="n">customresourcedefinition</span><span class="p">.</span><span class="n">apiextensions</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;globalnetworksets.crd.projectcalico.org&quot;</span> <span class="n">created</span>
<span class="n">customresourcedefinition</span><span class="p">.</span><span class="n">apiextensions</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;networkpolicies.crd.projectcalico.org&quot;</span> <span class="n">created</span>
<span class="n">serviceaccount</span> <span class="s">&quot;calico-node&quot;</span> <span class="n">created</span>
<span class="n">clusterrole</span><span class="p">.</span><span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;calico-node&quot;</span> <span class="n">created</span>
<span class="n">clusterrolebinding</span><span class="p">.</span><span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;calico-node&quot;</span> <span class="n">created</span>
<span class="n">deployment</span><span class="p">.</span><span class="n">extensions</span> <span class="s">&quot;calico-typha&quot;</span> <span class="n">created</span>
<span class="n">clusterrolebinding</span><span class="p">.</span><span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;typha-cpha&quot;</span> <span class="n">created</span>
<span class="n">clusterrole</span><span class="p">.</span><span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;typha-cpha&quot;</span> <span class="n">created</span>
<span class="n">configmap</span> <span class="s">&quot;calico-typha-horizontal-autoscaler&quot;</span> <span class="n">created</span>
<span class="n">deployment</span><span class="p">.</span><span class="n">extensions</span> <span class="s">&quot;calico-typha-horizontal-autoscaler&quot;</span> <span class="n">created</span>
<span class="n">role</span><span class="p">.</span><span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;typha-cpha&quot;</span> <span class="n">created</span>
<span class="n">serviceaccount</span> <span class="s">&quot;typha-cpha&quot;</span> <span class="n">created</span>
<span class="n">rolebinding</span><span class="p">.</span><span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span> <span class="s">&quot;typha-cpha&quot;</span> <span class="n">created</span>
<span class="n">service</span> <span class="s">&quot;calico-typha&quot;</span> <span class="n">created</span>
</pre></div>


<p>This will create a daemonset running the calico policy engine on each configured node.</p>
<p>Let's run a container with curl enabled to test our target system (hostname-v1 from the initial install):</p>
<div class="hlcode"><pre><span class="err">$</span> <span class="n">kubectl</span> <span class="n">run</span> <span class="o">--</span><span class="n">image</span> <span class="n">rstarmer</span><span class="o">/</span><span class="n">curl</span><span class="o">:</span><span class="n">v1</span> <span class="n">curl</span>
<span class="n">deployment</span><span class="p">.</span><span class="n">apps</span> <span class="s">&quot;curl&quot;</span> <span class="n">created</span>
</pre></div>


<p>And let's verify that we can communicate to the http://hostname-v1 service endpoint:</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span> <span class="o">-</span><span class="n">l</span> <span class="n">run</span><span class="o">=</span><span class="n">curl</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">items</span><span class="p">..</span><span class="n">metadata</span><span class="p">.</span><span class="n">name</span><span class="p">})</span>  <span class="o">--</span> <span class="n">curl</span> <span class="o">--</span><span class="n">connect</span><span class="o">-</span><span class="n">timeout</span> <span class="mi">5</span> <span class="n">http</span><span class="o">:</span><span class="c1">//hostname-v1</span>
</pre></div>


<p>Now, we can first disable network access by installing the baseline "Default Deny" policy, which will break our application access:</p>
<p>default-deny.yaml</p>
<div class="hlcode"><pre><span class="n">kind</span><span class="o">:</span> <span class="n">NetworkPolicy</span>
<span class="n">apiVersion</span><span class="o">:</span> <span class="n">networking</span><span class="o">.</span><span class="na">k8s</span><span class="o">.</span><span class="na">io</span><span class="o">/</span><span class="n">v1</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="k">default</span><span class="o">-</span><span class="n">deny</span>
  <span class="kd">namespace</span><span class="o">:</span> <span class="k">default</span>
<span class="n">spec</span><span class="o">:</span>
  <span class="n">podSelector</span><span class="o">:</span>
    <span class="n">matchLabels</span><span class="o">:</span> <span class="o">{}</span>
</pre></div>


<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">apply</span> <span class="o">-</span><span class="n">f</span> <span class="k">default</span><span class="o">-</span><span class="n">deny</span><span class="p">.</span><span class="n">yaml</span>
</pre></div>


<p>And check to see that we can't communicate:</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span> <span class="o">-</span><span class="n">l</span> <span class="n">run</span><span class="o">=</span><span class="n">curl</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">items</span><span class="p">..</span><span class="n">metadata</span><span class="p">.</span><span class="n">name</span><span class="p">})</span>  <span class="o">--</span> <span class="n">curl</span> <span class="o">--</span><span class="n">connect</span><span class="o">-</span><span class="n">timeout</span> <span class="mi">5</span> <span class="n">http</span><span class="o">:</span><span class="c1">//hostname-v1</span>
</pre></div>


<p>And then we can add back in a rule allowing access again:</p>
<p>allow-hostname.yaml</p>
<div class="hlcode"><pre><span class="n">kind</span><span class="o">:</span> <span class="n">NetworkPolicy</span>
<span class="n">apiVersion</span><span class="o">:</span> <span class="n">extensions</span><span class="o">/</span><span class="n">v1beta1</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="kd">namespace</span><span class="o">:</span> <span class="k">default</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">allow</span><span class="o">-</span><span class="n">hostname</span>
<span class="n">spec</span><span class="o">:</span>
  <span class="n">podSelector</span><span class="o">:</span>
    <span class="n">matchLabels</span><span class="o">:</span>
      <span class="n">app</span><span class="o">:</span> <span class="n">hostname</span><span class="o">-</span><span class="n">v1</span>
  <span class="n">ingress</span><span class="o">:</span>
    <span class="o">-</span> <span class="n">from</span><span class="o">:</span>
        <span class="o">-</span> <span class="n">namespaceSelector</span><span class="o">:</span>
            <span class="n">matchLabels</span><span class="o">:</span> <span class="o">{}</span>
</pre></div>


<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">apply</span> <span class="o">-</span><span class="n">f</span> <span class="n">allow</span><span class="o">-</span><span class="n">hostname</span><span class="p">.</span><span class="n">yaml</span>
</pre></div>


<p>And one more check:</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span> <span class="o">-</span><span class="n">l</span> <span class="n">run</span><span class="o">=</span><span class="n">curl</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">items</span><span class="p">..</span><span class="n">metadata</span><span class="p">.</span><span class="n">name</span><span class="p">})</span>  <span class="o">--</span> <span class="n">curl</span> <span class="o">--</span><span class="n">connect</span><span class="o">-</span><span class="n">timeout</span> <span class="mi">5</span> <span class="n">http</span><span class="o">:</span><span class="c1">//hostname-v1</span>
</pre></div>


<h2 id="adding-users">Adding Users</h2>
<p>Users within the EKS environment are authenticated against AWS IAM, which provides enhanced security.  If we add our 'clusterUser' credentials to the local aws client:</p>
<div class="hlcode"><pre><span class="n">cat</span> <span class="o">~/</span><span class="n">Downloads</span><span class="o">/</span><span class="n">credentials</span><span class="o">-</span><span class="mf">2.</span><span class="n">csv</span>

<span class="cp"># using above key and secret to access, region is us-west-2</span>
<span class="n">aws</span> <span class="n">configure</span> <span class="o">--</span><span class="n">profile</span><span class="o">=</span><span class="n">clusterUser</span>

<span class="n">export</span> <span class="n">AWS_PROFILE</span><span class="o">=</span><span class="n">clusterUser</span>
</pre></div>


<p>We will see that kubernetes will still try to talk to the API, but wil fail:</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pods</span>
</pre></div>


<p>Adding additional users to the kubernetes cluster in EKS is done by adding new<br />
users to the "system:masters" group which maps to the equivalent of the ClusterAdmin role in Kubernetes RBAC rules.</p>
<p>The key parameter we need is the User's IAM ARN, which can be pulled from the User IAM page in the AWS console:</p>
<p>aws-auth-cm.yaml</p>
<div class="hlcode"><pre><span class="n">apiVersion</span><span class="o">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="o">:</span> <span class="n">ConfigMap</span>
<span class="n">metadata</span><span class="o">:</span>
  <span class="n">name</span><span class="o">:</span> <span class="n">aws</span><span class="o">-</span><span class="n">auth</span>
  <span class="kd">namespace</span><span class="o">:</span> <span class="n">kube</span><span class="o">-</span><span class="n">system</span>
<span class="n">data</span><span class="o">:</span>
  <span class="n">mapUsers</span><span class="o">:</span> <span class="o">|</span>
    <span class="o">-</span> <span class="n">userarn</span><span class="o">:</span> <span class="n">USER</span><span class="o">-</span><span class="n">ARN</span>
      <span class="n">username</span><span class="o">:</span> <span class="n">admin</span>
      <span class="n">groups</span><span class="o">:</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">masters</span>
  <span class="n">mapRoles</span><span class="o">:</span> <span class="o">|</span>
    <span class="o">-</span> <span class="n">rolearn</span><span class="o">:</span> <span class="n">NODE</span><span class="o">-</span><span class="n">ROLE</span><span class="o">-</span><span class="n">ARN</span>
      <span class="n">username</span><span class="o">:</span> <span class="n">system</span><span class="o">:</span><span class="n">node</span><span class="o">:{{</span><span class="n">EC2PrivateDNSName</span><span class="o">}}</span>
      <span class="n">groups</span><span class="o">:</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">bootstrappers</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">nodes</span>
    <span class="o">-</span> <span class="n">rolearn</span><span class="o">:</span> <span class="n">LABEL</span><span class="o">-</span><span class="n">NODE</span><span class="o">-</span><span class="n">ROLE</span><span class="o">-</span><span class="n">ARN</span>
      <span class="n">username</span><span class="o">:</span> <span class="n">system</span><span class="o">:</span><span class="n">node</span><span class="o">:{{</span><span class="n">EC2PrivateDNSName</span><span class="o">}}</span>
      <span class="n">groups</span><span class="o">:</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">bootstrappers</span>
        <span class="o">-</span> <span class="n">system</span><span class="o">:</span><span class="n">nodes</span>
</pre></div>


<p>We need to add the mapUsers: section to the aws-auth-cm.yaml document, and we can do that either locally and "apply" the changes, or we can edit the document in place in the kubernetes service.</p>
<p>We will edit the file in place, as we don't want to have to recreate the worker node role mappings which are part of the same auth structure:</p>
<div class="hlcode"><pre><span class="n">export</span> <span class="n">AWS_PROFILE</span><span class="o">=</span><span class="n">clusterAdmin</span>
<span class="n">kubectl</span> <span class="n">edit</span> <span class="n">configmap</span> <span class="n">aws</span><span class="o">-</span><span class="n">auth</span> <span class="o">-</span><span class="n">n</span> <span class="n">kube</span><span class="o">-</span><span class="n">system</span>
</pre></div>


<p>Once we're done with the edit, we can switch back to our clusterUser and we should have access to the system:</p>
<div class="hlcode"><pre><span class="n">export</span> <span class="n">AWS_PROFILE</span><span class="o">=</span><span class="n">clusterUser</span>
<span class="n">kubectl</span> <span class="n">get</span> <span class="n">pods</span>
</pre></div>


<p>Add the mapUsers: section right after the data: key, above the mapRoles: | line. It should look similar to the aws-auth-cm.yaml document.</p>
<h2 id="install_prometheus">Install_Prometheus</h2>
<p>To add metrics to our Kubernetes environment, we'll use Helm to install Prometheus.</p>
<p>First we need helm installed as a client on our workstation, and then we can install the Kubernetes side component in our EKS system.  Get the helm binary for your environment here:</p>
<p>MacOSX:<br />
https://storage.googleapis.com/kubernetes-helm/helm-v2.11.0-darwin-amd64.tar.gz</p>
<p>Linux:<br />
https://storage.googleapis.com/kubernetes-helm/helm-v2.11.0-linux-amd64.tar.gz</p>
<p>Windows:<br />
https://storage.googleapis.com/kubernetes-helm/helm-v2.11.0-windows-amd64.zip</p>
<p>Or use a package manager.</p>
<p>Then we can install the RBAC configuration for tiller so that it has the appropriate access, and lastly we can initialize our helm system:</p>
<p>helm-rbac.yaml</p>
<div class="hlcode"><pre><span class="cp"># Create a service account for Helm and grant the cluster admin role.</span>
<span class="cp"># It is assumed that helm should be installed with this service account</span>
<span class="cp"># (tiller).</span>
<span class="nl">apiVersion:</span> <span class="n">v1</span>
<span class="nl">kind:</span> <span class="n">ServiceAccount</span>
<span class="nl">metadata:</span>
  <span class="nl">name:</span> <span class="n">tiller</span>
  <span class="nl">namespace:</span> <span class="n">kube</span><span class="o">-</span><span class="n">system</span>
<span class="o">---</span>
<span class="nl">apiVersion:</span> <span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span><span class="o">/</span><span class="n">v1beta1</span>
<span class="nl">kind:</span> <span class="n">ClusterRoleBinding</span>
<span class="nl">metadata:</span>
  <span class="nl">name:</span> <span class="n">tiller</span>
<span class="nl">roleRef:</span>
  <span class="nl">apiGroup:</span> <span class="n">rbac</span><span class="p">.</span><span class="n">authorization</span><span class="p">.</span><span class="n">k8s</span><span class="p">.</span><span class="n">io</span>
  <span class="nl">kind:</span> <span class="n">ClusterRole</span>
  <span class="nl">name:</span> <span class="n">cluster</span><span class="o">-</span><span class="n">admin</span>
<span class="nl">subjects:</span>
<span class="o">-</span> <span class="n">kind</span><span class="o">:</span> <span class="n">ServiceAccount</span>
  <span class="nl">name:</span> <span class="n">tiller</span>
  <span class="nl">namespace:</span> <span class="n">kube</span><span class="o">-</span><span class="n">system</span>
</pre></div>


<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">create</span> <span class="o">-</span><span class="n">f</span> <span class="n">helm</span><span class="o">-</span><span class="n">rbac</span><span class="p">.</span><span class="n">yaml</span>
<span class="n">helm</span> <span class="n">init</span> <span class="o">--</span><span class="n">service</span><span class="o">-</span><span class="n">account</span><span class="o">=</span><span class="n">tiller</span>
</pre></div>


<p>Once Helm is installed, launching Prometheus is a simple command, though note that we are defining the storage class that Prometheus should use to store it's metrics:</p>
<div class="hlcode"><pre><span class="n">helm</span> <span class="n">install</span> <span class="o">--</span><span class="n">name</span> <span class="n">promeks</span> <span class="o">--</span><span class="n">set</span> <span class="n">server</span><span class="p">.</span><span class="n">persistentVolume</span><span class="p">.</span><span class="n">storageClass</span><span class="o">=</span><span class="n">gp2</span> <span class="n">stable</span><span class="o">/</span><span class="n">prometheus</span>
</pre></div>


<p>And lastly, we want to expose the Prometheus UI so that we can have a look at some of the Pod/Container level metrics:</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="o">--</span><span class="n">namespace</span> <span class="k">default</span> <span class="n">port</span><span class="o">-</span><span class="n">forward</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pods</span> <span class="o">--</span><span class="n">namespace</span> <span class="k">default</span> <span class="o">-</span><span class="n">l</span> <span class="s">&quot;app=prometheus,component=server&quot;</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="s">&quot;{.items[0].metadata.name}&quot;</span><span class="p">)</span> <span class="mi">9090</span> <span class="o">&amp;</span>
</pre></div>


<p>Once the portforward is working, we can point a web browser at:</p>
<p>http://localhost:9090</p>
<p>look to see what metrics are being gathered.</p>
<p>container_cpu_usage_seconds_total</p>
<p>And we can also generate a little load if we'd like:</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">run</span> <span class="o">--</span><span class="n">image</span> <span class="n">rstarmer</span><span class="o">/</span><span class="n">curl</span><span class="o">:</span><span class="n">v1</span> <span class="n">curl</span>
<span class="n">kubectl</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="err">$</span><span class="p">(</span><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span> <span class="o">-</span><span class="n">l</span> <span class="n">run</span><span class="o">=</span><span class="n">curl</span> <span class="o">-</span><span class="n">o</span> <span class="n">jsonpath</span><span class="o">=</span><span class="p">{.</span><span class="n">items</span><span class="p">..</span><span class="n">metadata</span><span class="p">.</span><span class="n">name</span><span class="p">})</span> <span class="o">--</span> \
<span class="n">sh</span> <span class="o">-</span><span class="n">c</span> <span class="err">&#39;</span><span class="k">while</span> <span class="p">[[</span> <span class="nb">true</span> <span class="p">]];</span> <span class="k">do</span> <span class="n">curl</span> <span class="o">-</span><span class="n">o</span> <span class="o">-</span> <span class="n">http</span><span class="o">:</span><span class="c1">//hostname-v1/version/ ; done&#39;</span>
</pre></div>
    </div>
    <div id="footer">
      <span>
        <p>Copyright Â© 2019 Xu XueHua.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2019-04-02 00:07:18</p>
      </span>
    </div>

    
    
  </body>
</html>